# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-02-28

## Code
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Multi-Turn Code Generation Through Single-Step Rewards](http://arxiv.org/abs/2502.20380v1)** | 2025-02-27 | <details><summary>Show</summary><p>We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $\mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode.</p></details> | <details><summary>9 pag...</summary><p>9 pages (not including references or appendix); 6 figures (in main paper); (v1) preprint</p></details> |
| **[Moderate-length lifted quantum Tanner codes](http://arxiv.org/abs/2502.20297v1)** | 2025-02-27 | <details><summary>Show</summary><p>We introduce new families of quantum Tanner codes, a class of quantum codes which first appeared in the work of Leverrier and Z\'emor. These codes are built from two classical Tanner codes, for which the underlying graphs are extracted from coverings of 2D geometrical complexes, and the local linear codes are tensor-product of cyclic or double-circulant linear codes. We present several explicit families, and identify instances of moderate length quantum codes which are degenerate, have low check weight, and for which the distance surpasses the square root of the code length. Among them, we report the existence of a $[[96,2,12]]$ code, for which half of the checks are of weight 8 and the other half of weight 4.</p></details> |  |
| **[Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets](http://arxiv.org/abs/2502.20246v1)** | 2025-02-27 | <details><summary>Show</summary><p>The increasing adoption of large language models (LLMs) for code-related tasks has raised concerns about the security of their training datasets. One critical threat is dead code poisoning, where syntactically valid but functionally redundant code is injected into training data to manipulate model behavior. Such attacks can degrade the performance of neural code search systems, leading to biased or insecure code suggestions. Existing detection methods, such as token-level perplexity analysis, fail to effectively identify dead code due to the structural and contextual characteristics of programming languages. In this paper, we propose DePA (Dead Code Perplexity Analysis), a novel line-level detection and cleansing method tailored to the structural properties of code. DePA computes line-level perplexity by leveraging the contextual relationships between code lines and identifies anomalous lines by comparing their perplexity to the overall distribution within the file. Our experiments on benchmark datasets demonstrate that DePA significantly outperforms existing methods, achieving 0.14-0.19 improvement in detection F1-score and a 44-65% increase in poisoned segment localization precision. Furthermore, DePA enhances detection speed by 0.62-23x, making it practical for large-scale dataset cleansing. Overall, by addressing the unique challenges of dead code poisoning, DePA provides a robust and efficient solution for safeguarding the integrity of code generation model training datasets.</p></details> |  |
| **[Code Style Sheets: CSS for Code](http://arxiv.org/abs/2502.09386v5)** | 2025-02-27 | <details><summary>Show</summary><p>Program text is rendered using impoverished typographic styles. Beyond choice of fonts and syntax-highlighting colors, code editors and related tools utilize very few text decorations. These limited styles are, furthermore, applied in monolithic fashion, regardless of the programs and tasks at hand. We present the notion of _code style sheets_ for styling program text. Motivated by analogy to cascading style sheets (CSS) for styling HTML documents, code style sheets provide mechanisms for defining rules to select elements from an abstract syntax tree (AST) in order to style their corresponding visual representation. Technically, our selector language generalizes essential constructs from CSS to a programming-language setting with algebraic data types (such as ASTs). Practically, code style sheets allow ASTs to be styled granularly, based on semantic information -- such as the structure of abstract syntax, static type information, and corresponding run-time values -- as well as design choices on the part of authors and readers of a program. Because programs are heavily nested in structure, a key aspect of our design is a layout algorithm that renders nested, multiline text blocks more compactly than in existing box-based layout systems such as HTML. In this paper, we design and implement a code style sheets system for a subset of Haskell, using it to illustrate several code presentation and visualization tasks. These examples demonstrate that code style sheets provide a uniform framework for rendering programs in multivarious ways, which could be employed in future designs for text-based as well as structure editors.</p></details> | <details><summary>OOPSL...</summary><p>OOPSLA 2025 Paper + Appendices</p></details> |
| **[Effective Distance of Higher Dimensional HGPs and Weight-Reduced Quantum LDPC Codes](http://arxiv.org/abs/2409.02193v4)** | 2025-02-27 | <details><summary>Show</summary><p>Quantum error correction plays a prominent role in the realization of quantum computation, and quantum low-density parity-check (qLDPC) codes are believed to be practically useful stabilizer codes. While qLDPC codes are defined to have constant weight parity-checks, the weight of these parity checks could be large constants that make implementing these codes challenging. Large constants can also result in long syndrome extraction times and bad error propagation that can impact error correction performance. Hastings recently introduced weight reduction techniques for qLDPC codes that reduce the weight of the parity checks as well as the maximum number of checks that acts on any data qubit. However, the fault tolerance of these techniques remains an open question. In this paper, we analyze the effective distance of the weight-reduced code when single-ancilla syndrome extraction circuits are considered for error correction. We prove that there exists single-ancilla syndrome extraction circuits that largely preserve the effective distance of the weight-reduced qLDPC codes. In addition, we also show that the distance balancing technique introduced by Evra et al. preserves effective distance. As a corollary, our result shows that higher-dimensional hypergraph product (HGP) codes, also known as homological product codes corresponding to the product of 1-complexes, have no troublesome hook errors when using any single-ancilla syndrome extraction circuit.</p></details> | <details><summary>Updat...</summary><p>Updated the manuscript to include distance preservation for coning for completeness</p></details> |
| **[On Designing Novel ISI-Reducing Single Error Correcting Codes in an MCvD System](http://arxiv.org/abs/2502.19943v1)** | 2025-02-27 | <details><summary>Show</summary><p>Intersymbol Interference (ISI) has a detrimental impact on any Molecular Communication via Diffusion (MCvD) system. Also, the receiver noise can severely degrade the MCvD channel performance. However, the channel codes proposed in the literature for the MCvD system have only addressed one of these two challenges independently. In this paper, we have designed single Error Correcting Codes in an MCvD system with channel memory and noise. We have also provided encoding and decoding algorithms for the proposed codes, which are simple to follow despite having a non-linear code construction. Finally, through simulation results, we show that the proposed single ECCs, for given code parameters, perform better than the existing codes in the literature in combating the effect of ISI in the channel and improving the average Bit Error Rate (BER) performance in a noisy channel.</p></details> | 5 pages, 5 figures |
| **[A Cooperative Repair Scheme for Zigzag MSR Codes in Distributed Storage Systems](http://arxiv.org/abs/2502.19909v1)** | 2025-02-27 | <details><summary>Show</summary><p>In this paper, we propose a novel cooperative repair scheme for Zigzag MSR codes with optimal repair bandwidth, enabling the repair of any h failed nodes. To the best of our knowledge, this is the first optimal cooperative repair scheme for Zigzag MSR codes. Compared to previous cooperative repair schemes for MSR codes, our scheme significantly reduces the size of the finite field to Fq,q>=n+1.</p></details> |  |
| **[NeRFCom: Feature Transform Coding Meets Neural Radiance Field for Free-View 3D Scene Semantic Transmission](http://arxiv.org/abs/2502.19873v1)** | 2025-02-27 | <details><summary>Show</summary><p>We introduce NeRFCom, a novel communication system designed for end-to-end 3D scene transmission. Compared to traditional systems relying on handcrafted NeRF semantic feature decomposition for compression and well-adaptive channel coding for transmission error correction, our NeRFCom employs a nonlinear transform and learned probabilistic models, enabling flexible variable-rate joint source-channel coding and efficient bandwidth allocation aligned with the NeRF semantic feature's different contribution to the 3D scene synthesis fidelity. Experimental results demonstrate that NeRFCom achieves free-view 3D scene efficient transmission while maintaining robustness under adverse channel conditions.</p></details> |  |
| **[ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments](http://arxiv.org/abs/2502.19852v1)** | 2025-02-27 | <details><summary>Show</summary><p>Large language models (LLMs) have proven invaluable for code generation, particularly in interactive settings. However, existing code generation benchmarks fail to capture the diverse feedback encountered in multi-turn interactions, limiting our ability to evaluate LLMs in these contexts. To address this gap, we present a set of novel benchmarks that explicitly model the quality of feedback provided to code generation LLMs. Our contributions are threefold: First, we introduce CONVCODEWORLD, a novel and reproducible environment for benchmarking interactive code generation. CONVCODEWORLD simulates 9 distinct interactive code generation scenarios while systematically combining three types of feedback: (a) compilation feedback; (b) execution feedback with varying test coverage; (c) verbal feedback generated by GPT-4o with different levels of expertise. Second, we introduce CONVCODEBENCH, a fast, static version of benchmark that uses pre-generated feedback logs, eliminating the need for costly dynamic verbal feedback generation while maintaining strong Spearman's rank correlations (0.82 to 0.99) with CONVCODEWORLD. Third, extensive evaluations of both closed-source and open-source LLMs including R1-Distill on CONVCODEWORLD reveal key insights: (a) LLM performance varies significantly based on the feedback provided; (b) Weaker LLMs, with sufficient feedback, can outperform single-turn results of state-of-the-art LLMs without feedback; (c) Training on a specific feedback combination can limit an LLM's ability to utilize unseen combinations; (d) LLMs solve problems in fewer turns (high MRR) may not solve as many problems overall (high Recall), and vice versa. All implementations and benchmarks will be made publicly available at https://huggingface.co/spaces/ConvCodeWorld/ConvCodeWorld</p></details> | ICLR 2025 |
| **[MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training](http://arxiv.org/abs/2502.08904v3)** | 2025-02-27 | <details><summary>Show</summary><p>Recent methodologies utilizing synthetic datasets have aimed to address inconsistent hallucinations in large language models (LLMs); however,these approaches are primarily tailored to specific tasks, limiting their generalizability. Inspired by the strong performance of code-trained models in logic-intensive domains, we propose a novel framework that leverages event-based text to generate corresponding code and employs cyclic training to transfer the logical consistency of code to natural language effectively. Our method significantly reduces inconsistent hallucinations across three leading LLMs and two categories of natural language tasks while maintaining overall performance. This framework effectively alleviates hallucinations without necessitating adaptation to downstream tasks, demonstrating generality and providing new perspectives to tackle the challenge of inconsistent hallucinations.</p></details> |  |
| **[CodeRAG-Bench: Can Retrieval Augment Code Generation?](http://arxiv.org/abs/2406.14497v2)** | 2025-02-26 | <details><summary>Show</summary><p>While language models (LMs) have proven remarkably adept at generating code, many programs are challenging for LMs to generate using their parametric knowledge alone. Providing external contexts such as library documentation can facilitate generating accurate and functional code. Despite the success of retrieval-augmented generation (RAG) in various text-oriented tasks, its potential for improving code generation remains under-explored. In this work, we conduct a systematic, large-scale analysis by asking: in what scenarios can retrieval benefit code generation models? and what challenges remain? We first curate a comprehensive evaluation benchmark, CodeRAG-Bench, encompassing three categories of code generation tasks, including basic programming, open-domain, and repository-level problems. We aggregate documents from five sources for models to retrieve contexts: competition solutions, online tutorials, library documentation, StackOverflow posts, and GitHub repositories. We examine top-performing models on CodeRAG-Bench by providing contexts retrieved from one or multiple sources. While notable gains are made in final code generation by retrieving high-quality contexts across various settings, our analysis reveals room for improvement -- current retrievers still struggle to fetch useful contexts especially with limited lexical overlap, and generators fail to improve with limited context lengths or abilities to integrate additional contexts. We hope CodeRAG-Bench serves as an effective testbed to encourage further development of advanced code-oriented RAG methods.</p></details> |  |
| **[CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback](http://arxiv.org/abs/2411.09073v2)** | 2025-02-26 | <details><summary>Show</summary><p>Large Language Models (LLMs) have demonstrated remarkable capabilities across various NLP tasks but struggle with code-mixed (or code-switched) language understanding. For example, prior work benchmarking the performance of multilingual LLMs on code-mixed translation tasks has demonstrated that current state-of-the-art multilingual LLMs are ineffective in dealing with code-mixed languages. However, the question of how to improve the capability of multilingual LLMs to handle code-mixed language has not received any attention to date. In this paper, we tackle this research gap by proposing CHAI, a novel general-purpose framework for improving the ability of multilingual LLMs to handle code-mixed languages. CHAI relies on three novel contributions made in this paper. First, we explore the ability of LLMs to provide accurate annotations for code-mixed translation tasks. Second, we leverage this ability of LLMs as annotators to generate preference data for code-mixed translation tasks at scale, which are then used within a reinforcement learning from AI feedback (RLAIF) procedure to improve LLMs' capability on code-mixed tasks. Third, we conduct a rigorous experimental evaluation across various real-world datasets and settings. Our analysis shows that CHAI-powered LLMs outperform state-of-the-art open-source LLMs by 25.66% (in terms of win rate adjudicated by human annotators) in code-mixed translation tasks. This work represents a first step towards developing more inclusive code-mixed LLMs.</p></details> | <details><summary>full ...</summary><p>full draft: 8 pages, 2 figures</p></details> |
| **[Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs](http://arxiv.org/abs/2502.19411v1)** | 2025-02-26 | <details><summary>Show</summary><p>In large language models (LLMs), code and reasoning reinforce each other: code offers an abstract, modular, and logic-driven structure that supports reasoning, while reasoning translates high-level goals into smaller, executable steps that drive more advanced code intelligence. In this study, we examine how code serves as a structured medium for enhancing reasoning: it provides verifiable execution paths, enforces logical decomposition, and enables runtime validation. We also explore how improvements in reasoning have transformed code intelligence from basic completion to advanced capabilities, enabling models to address complex software engineering tasks through planning and debugging. Finally, we identify key challenges and propose future research directions to strengthen this synergy, ultimately improving LLM's performance in both areas.</p></details> | <details><summary>Proje...</summary><p>Project Repo: https://github.com/dayuyang1999/Awesome-Code-Reasoning</p></details> |
| **[Learning Code-Edit Embedding to Model Student Debugging Behavior](http://arxiv.org/abs/2502.19407v1)** | 2025-02-26 | <details><summary>Show</summary><p>Providing effective feedback for programming assignments in computer science education can be challenging: students solve problems by iteratively submitting code, executing it, and using limited feedback from the compiler or the auto-grader to debug. Analyzing student debugging behavior in this process may reveal important insights into their knowledge and inform better personalized support tools. In this work, we propose an encoder-decoder-based model that learns meaningful code-edit embeddings between consecutive student code submissions, to capture their debugging behavior. Our model leverages information on whether a student code submission passes each test case to fine-tune large language models (LLMs) to learn code editing representations. It enables personalized next-step code suggestions that maintain the student's coding style while improving test case correctness. Our model also enables us to analyze student code-editing patterns to uncover common student errors and debugging behaviors, using clustering techniques. Experimental results on a real-world student code submission dataset demonstrate that our model excels at code reconstruction and personalized code suggestion while revealing interesting patterns in student debugging behavior.</p></details> |  |
| **[Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code](http://arxiv.org/abs/2412.02764v2)** | 2025-02-26 | <details><summary>Show</summary><p>This paper introduces the human-curated PandasPlotBench dataset, designed to evaluate language models' effectiveness as assistants in visual data exploration. Our benchmark focuses on generating code for visualizing tabular data - such as a Pandas DataFrame - based on natural language instructions, complementing current evaluation tools and expanding their scope. The dataset includes 175 unique tasks. Our experiments assess several leading Large Language Models (LLMs) across three visualization libraries: Matplotlib, Seaborn, and Plotly. We show that the shortening of tasks has a minimal effect on plotting capabilities, allowing for the user interface that accommodates concise user input without sacrificing functionality or accuracy. Another of our findings reveals that while LLMs perform well with popular libraries like Matplotlib and Seaborn, challenges persist with Plotly, highlighting areas for improvement. We hope that the modular design of our benchmark will broaden the current studies on generating visualizations. Our dataset and benchmark code are available online: https://huggingface.co/datasets/JetBrains-Research/PandasPlotBench; https://github.com/JetBrains-Research/PandasPlotBench.</p></details> | 5 pages |
| **[UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation](http://arxiv.org/abs/2502.12490v3)** | 2025-02-26 | <details><summary>Show</summary><p>Deep learning-based code generation has completely transformed the way developers write programs today. Existing approaches to code generation have focused either on the Sequence-to-Sequence paradigm, which generates target code as a sequence of tokens, or the Sequence-to-Tree paradigm, which outputs code as a sequence of actions. While these two paradigms are intuitively complementary, their combination has not been previously explored. By comparing the code generated under these two paradigms, we find that integrating them holds significant potential. In this paper, we propose UniGenCoder for code-related generation tasks, which consists of a shared encoder, a shared decoder with a minimal set of additional parameters to unify two paradigms, and a selector that dynamically chooses optimal paradigm for each instance. Also, during the model training, we first perform the multi-task learning and distillation strategies to facilitate knowledge transfer between two paradigms, and then leverage contrastive learning to train the selector. Experimental results on the text-to-code and code-to-code generation tasks demonstrate the effectiveness of our proposed model. We release our code at https://github.com/DeepLearnXMU/UniGenCoder.</p></details> | <details><summary>accep...</summary><p>accepted to 47th International Conference on Software Engineering (ICSE 2025), NIER track</p></details> |
| **[Detecting Essence Code Clones via Information Theoretic Analysis](http://arxiv.org/abs/2502.19219v1)** | 2025-02-26 | <details><summary>Show</summary><p>Code cloning, a widespread practice in software development, involves replicating code fragments to save time but often at the expense of software maintainability and quality. In this paper, we address the specific challenge of detecting "essence clones", a complex subtype of Type-3 clones characterized by sharing critical logic despite different peripheral codes. Traditional techniques often fail to detect essence clones due to their syntactic focus. To overcome this limitation, we introduce ECScan, a novel detection tool that leverages information theory to assess the semantic importance of code lines. By assigning weights to each line based on its information content, ECScan emphasizes core logic over peripheral code differences. Our comprehensive evaluation across various real-world projects shows that ECScan significantly outperforms existing tools in detecting essence clones, achieving an average F1-score of 85%. It demonstrates robust performance across all clone types and offers exceptional scalability. This study advances clone detection by providing a practical tool for developers to enhance code quality and reduce maintenance burdens, emphasizing the semantic aspects of code through an innovative information-theoretic approach.</p></details> |  |
| **[Prompting Techniques for Secure Code Generation: A Systematic Investigation](http://arxiv.org/abs/2407.07064v2)** | 2025-02-26 | <details><summary>Show</summary><p>Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions. However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software. Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs. Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations. OBJECTIVE: In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs. METHOD: First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation. For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts. RESULTS: Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security.</p></details> | <details><summary>Work ...</summary><p>Work partially supported by the EU-funded project Sec4AI4Sec: Cybersecurity for AI-Augmented Systems (grant no. 101120393) - ACCEPTED at ACM Transactions on Software Engineering and Methodology (Feb. 2025)</p></details> |
| **[CodeIF: Benchmarking the Instruction-Following Capabilities of Large Language Models for Code Generation](http://arxiv.org/abs/2502.19166v1)** | 2025-02-26 | <details><summary>Show</summary><p>With the rapid advancement of Large Language Models (LLMs), the demand for robust instruction-following capabilities in code generation tasks has grown significantly. Code generation not only facilitates faster prototyping and automated testing, but also augments developer efficiency through improved maintainability and reusability of code. In this paper, we introduce CodeIF, the first benchmark specifically designed to assess the abilities of LLMs to adhere to task-oriented instructions within diverse code generation scenarios. CodeIF encompasses a broad range of tasks, including function synthesis, error debugging, algorithmic refactoring, and code explanation, thereby providing a comprehensive suite to evaluate model performance across varying complexity levels and programming domains. We conduct extensive experiments with LLMs, analyzing their strengths and limitations in meeting the demands of these tasks. The experimental results offer valuable insights into how well current models align with human instructions, as well as the extent to which they can generate consistent, maintainable, and contextually relevant code. Our findings not only underscore the critical role that instruction-following LLMs can play in modern software development, but also illuminate pathways for future research aimed at enhancing their adaptability, reliability, and overall effectiveness in automated code generation.</p></details> |  |
| **[Isolating Language-Coding from Problem-Solving: Benchmarking LLMs with PseudoEval](http://arxiv.org/abs/2502.19149v1)** | 2025-02-26 | <details><summary>Show</summary><p>Existing code generation benchmarks for Large Language Models (LLMs) such as HumanEval and MBPP are designed to study LLMs' end-to-end performance, where the benchmarks feed a problem description in natural language as input and examine the generated code in specific programming languages. However, the evaluation scores revealed in this way provide a little hint as to the bottleneck of the code generation -- whether LLMs are struggling with their problem-solving capability or language-coding capability. To answer this question, we construct PseudoEval, a multilingual code generation benchmark that provides a solution written in pseudocode as input. By doing so, the bottleneck of code generation in various programming languages could be isolated and identified. Our study yields several interesting findings. For example, we identify that the bottleneck of LLMs in Python programming is problem-solving, while Rust is struggling relatively more in language-coding. Also, our study indicates that problem-solving capability may transfer across programming languages, while language-coding needs more language-specific effort, especially for undertrained programming languages. Finally, we release the pipeline of constructing PseudoEval to facilitate the extension to existing benchmarks. PseudoEval is available at: https://anonymous.4open.science/r/PseudocodeACL25-7B74.</p></details> |  |
| **[Cylindrical and Möbius Quantum Codes for Asymmetric Pauli Errors](http://arxiv.org/abs/2502.19089v1)** | 2025-02-26 | <details><summary>Show</summary><p>In the implementation of quantum information systems, one type of Pauli error, such as phase-flip errors, may occur more frequently than others, like bit-flip errors. For this reason, quantum error-correcting codes that handle asymmetric errors are critical to mitigating the impact of such impairments. To this aim, several asymmetric quantum codes have been proposed. These include variants of surface codes like the XZZX and ZZZY surface codes, tailored to preserve quantum information in the presence of error asymmetries. In this work, we propose two classes of Calderbank, Shor and Steane (CSS) topological codes, referred to as cylindrical and M\"obius codes, particular cases of the fiber bundle family. Cylindrical codes maintain a fully planar structure, while M\"obius codes are quasi-planar, with minimal non-local qubit interactions. We construct these codes employing the algebraic chain complexes formalism, providing theoretical upper bounds for the logical error rate. Our results demonstrate that cylindrical and M\"obius codes outperform standard surface codes when using the minimum weight perfect matching (MWPM) decoder.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 8 figures, submitted to a journal</p></details> |
| **[IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages](http://arxiv.org/abs/2502.19067v1)** | 2025-02-26 | <details><summary>Show</summary><p>Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation from natural language prompts, revolutionizing software development workflows. As we advance towards agent-based development paradigms, these models form the cornerstone of next-generation software development lifecycles. However, current benchmarks for evaluating multilingual code generation capabilities are predominantly English-centric, limiting their applicability across the global developer community. To address this limitation, we present IndicEval-XL, a comprehensive benchmark for code generation that incorporates 6 major Indic languages, collectively spoken by approximately 14\% of the world's population. Our benchmark bridges these languages with 12 programming languages, creating a robust evaluation framework. This work is particularly significant given India's representation of one-eighth of the global population and the crucial role Indic languages play in Indian society. IndicEval-XL represents a significant step toward expanding the linguistic diversity in code generation systems and evaluation frameworks. By developing resources that support multiple languages, we aim to make AI-powered development tools more inclusive and accessible to developers of various linguistic backgrounds. To facilitate further research and development in this direction, we make our dataset and evaluation benchmark publicly available at https://github.com/telekom/IndicEval-XL</p></details> |  |
| **[OntologyRAG: Better and Faster Biomedical Code Mapping with Retrieval-Augmented Generation (RAG) Leveraging Ontology Knowledge Graphs and Large Language Models](http://arxiv.org/abs/2502.18992v1)** | 2025-02-26 | <details><summary>Show</summary><p>Biomedical ontologies, which comprehensively define concepts and relations for biomedical entities, are crucial for structuring and formalizing domain-specific information representations. Biomedical code mapping identifies similarity or equivalence between concepts from different ontologies. Obtaining high-quality mapping usually relies on automatic generation of unrefined mapping with ontology domain fine-tuned language models (LMs), followed by manual selections or corrections by coding experts who have extensive domain expertise and familiarity with ontology schemas. The LMs usually provide unrefined code mapping suggestions as a list of candidates without reasoning or supporting evidence, hence coding experts still need to verify each suggested candidate against ontology sources to pick the best matches. This is also a recurring task as ontology sources are updated regularly to incorporate new research findings. Consequently, the need of regular LM retraining and manual refinement make code mapping time-consuming and labour intensive. In this work, we created OntologyRAG, an ontology-enhanced retrieval-augmented generation (RAG) method that leverages the inductive biases from ontological knowledge graphs for in-context-learning (ICL) in large language models (LLMs). Our solution grounds LLMs to knowledge graphs with unrefined mappings between ontologies and processes questions by generating an interpretable set of results that include prediction rational with mapping proximity assessment. Our solution doesn't require re-training LMs, as all ontology updates could be reflected by updating the knowledge graphs with a standard process. Evaluation results on a self-curated gold dataset show promises of using our method to enable coding experts to achieve better and faster code mapping. The code is available at https://github.com/iqvianlp/ontologyRAG.</p></details> | <details><summary>This ...</summary><p>This paper has been accepted as a workshop paper for KEIR@ECIR 2025</p></details> |
| **[CS-Dialogue: A 104-Hour Dataset of Spontaneous Mandarin-English Code-Switching Dialogues for Speech Recognition](http://arxiv.org/abs/2502.18913v1)** | 2025-02-26 | <details><summary>Show</summary><p>Code-switching (CS), the alternation between two or more languages within a single conversation, presents significant challenges for automatic speech recognition (ASR) systems. Existing Mandarin-English code-switching datasets often suffer from limitations in size, spontaneity, and the lack of full-length dialogue recordings with transcriptions, hindering the development of robust ASR models for real-world conversational scenarios. This paper introduces CS-Dialogue, a novel large-scale Mandarin-English code-switching speech dataset comprising 104 hours of spontaneous conversations from 200 speakers. Unlike previous datasets, CS-Dialogue provides full-length dialogue recordings with complete transcriptions, capturing naturalistic code-switching patterns in continuous speech. We describe the data collection and annotation processes, present detailed statistics of the dataset, and establish benchmark ASR performance using state-of-the-art models. Our experiments, using Transformer, Conformer, and Branchformer, demonstrate the challenges of code-switching ASR, and show that existing pre-trained models such as Whisper still have the space to improve. The CS-Dialogue dataset will be made freely available for all academic purposes.</p></details> |  |
| **[Automated Code Generation and Validation for Software Components of Microcontrollers](http://arxiv.org/abs/2502.18905v1)** | 2025-02-26 | <details><summary>Show</summary><p>This paper proposes a method for generating software components for embedded systems, integrating seamlessly into existing implementations without developer intervention. We demonstrate this by automatically generating hardware abstraction layer (HAL) code for GPIO operations on the STM32F407 microcontroller. Using Abstract Syntax Trees (AST) for code analysis and Retrieval-Augmented Generation (RAG) for component generation, our approach enables autonomous code completion for embedded applications.</p></details> | <details><summary>Sebas...</summary><p>Sebastian Haug: This paper, spanning 12 pages with 5 figures, presents my work on automated code generation and validation for STM32F407 microcontroller software components. Developed as part of a research project at Munich University of Applied Sciences and AGSOTEC GmbH, it leverages AST and RAG to streamline embedded development. Includes glossary and bibliography as supplementary materials</p></details> |
| **[Towards More Trustworthy Deep Code Models by Enabling Out-of-Distribution Detection](http://arxiv.org/abs/2502.18883v1)** | 2025-02-26 | <details><summary>Show</summary><p>Numerous machine learning (ML) models have been developed, including those for software engineering (SE) tasks, under the assumption that training and testing data come from the same distribution. However, training and testing distributions often differ, as training datasets rarely encompass the entire distribution, while testing distribution tends to shift over time. Hence, when confronted with out-of-distribution (OOD) instances that differ from the training data, a reliable and trustworthy SE ML model must be capable of detecting them to either abstain from making predictions, or potentially forward these OODs to appropriate models handling other categories or tasks. In this paper, we develop two types of SE-specific OOD detection models, unsupervised and weakly-supervised OOD detection for code. The unsupervised OOD detection approach is trained solely on in-distribution samples while the weakly-supervised approach utilizes a tiny number of OOD samples to further enhance the detection performance in various OOD scenarios. Extensive experimental results demonstrate that our proposed methods significantly outperform the baselines in detecting OOD samples from four different scenarios simultaneously and also positively impact a main code understanding task.</p></details> |  |
| **[Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code](http://arxiv.org/abs/2502.18851v1)** | 2025-02-26 | <details><summary>Show</summary><p>Code watermarking identifies AI-generated code by embedding patterns into the code during generation. Effective watermarking requires meeting two key conditions: the watermark should be reliably detectable, and the code should retain its original functionality. However, existing methods often modify tokens that are critical for program logic, such as keywords in conditional expressions or operators in arithmetic computations. These modifications can cause syntax errors or functional failures, limiting the practical use of watermarking. We present STONE, a method that preserves functional integrity by selectively inserting watermarks only into non-syntax tokens. By excluding tokens essential for code execution, STONE minimizes the risk of functional degradation. In addition, we introduce CWEM, a comprehensive evaluation metric that evaluates watermarking techniques based on correctness, detectability, and naturalness. While correctness and detectability have been widely used, naturalness remains underexplored despite its importance. Unnatural patterns can reveal the presence of a watermark, making it easier for adversaries to remove. We evaluate STONE using CWEM and compare its performance with the state-of-the-art approach. The results show that STONE achieves an average improvement of 7.69% in CWEM across Python, C++, and Java. Our code is available in https://github.com/inistory/STONE-watermarking/.</p></details> |  |
| **[MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs](http://arxiv.org/abs/2502.14916v2)** | 2025-02-26 | <details><summary>Show</summary><p>The task of automatically coding the International Classification of Diseases (ICD) in the medical field has been well-established and has received much attention. Automatic coding of the ICD in the medical field has been successful in English but faces challenges when dealing with Chinese electronic medical records (EMRs). The first issue lies in the difficulty of extracting disease code-related information from Chinese EMRs, primarily due to the concise writing style and specific internal structure of the EMRs. The second problem is that previous methods have failed to leverage the disease-based multi-axial knowledge and lack of association with the corresponding clinical evidence. This paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge with Evidence verification in ICD coding for Chinese EMRs. Initially, we identify candidate codes for the diagnosis and categorize each of them into knowledge under four coding axes.Subsequently, we retrieve corresponding clinical evidence from the comprehensive content of EMRs and filter credible evidence through a scoring model. Finally, to ensure the validity of the candidate code, we propose an inference module based on the masked language modeling strategy. This module verifies that all the axis knowledge associated with the candidate code is supported by evidence and provides recommendations accordingly. To evaluate the performance of our framework, we conduct experiments using a large-scale Chinese EMR dataset collected from various hospitals. The experimental results demonstrate that MKE-Coder exhibits significant superiority in the task of automatic ICD coding based on Chinese EMRs. In the practical evaluation of our method within simulated real coding scenarios, it has been demonstrated that our approach significantly aids coders in enhancing both their coding accuracy and speed.</p></details> |  |
| **[SolEval: Benchmarking Large Language Models for Repository-level Solidity Code Generation](http://arxiv.org/abs/2502.18793v1)** | 2025-02-26 | <details><summary>Show</summary><p>Large language models (LLMs) have transformed code generation. However, most existing approaches focus on mainstream languages such as Python and Java, neglecting the Solidity language, the predominant programming language for Ethereum smart contracts. Due to the lack of adequate benchmarks for Solidity, LLMs' ability to generate secure, cost-effective smart contracts remains unexplored. To fill this gap, we construct SolEval, the first repository-level benchmark designed for Solidity smart contract generation, to evaluate the performance of LLMs on Solidity. SolEval consists of 1,125 samples from 9 different repositories, covering 6 popular domains, providing LLMs with a comprehensive evaluation benchmark. Unlike the existing Solidity benchmark, SolEval not only includes complex function calls but also reflects the real-world complexity of the Ethereum ecosystem by incorporating gas fee and vulnerability rate. We evaluate 10 LLMs on SolEval, and our results show that the best-performing LLM achieves only 26.29% Pass@10, highlighting substantial room for improvement in Solidity code generation by LLMs. We release our data and code at https://anonymous.4open.science/r/SolEval-1C06/.</p></details> |  |
| **[On the Existence of Galois Self-Dual GRS and TGRS Codes](http://arxiv.org/abs/2210.10562v4)** | 2025-02-26 | <details><summary>Show</summary><p>Let $q=p^m$ be a prime power and $e$ be an integer with $0\leq e\leq m-1$. $e$-Galois self-dual codes are generalizations of Euclidean $(e=0)$ and Hermitian ($e=\frac{m}{2}$ with even $m$) self-dual codes. In this paper, for a linear code $\C$ and a nonzero vector $\bm{u}\in \F_q^n$, we give a sufficient and necessary condition for the dual extended code $\underline{\C}[\bm{u}]$ of $\C$ to be $e$-Galois self-orthogonal. From this, a new systematic approach is proposed to prove the existence of $e$-Galois self-dual codes. By this method, we prove that $e$-Galois self-dual (extended) generalized Reed-Solomon (GRS) codes of length $n>\min\{p^e+1,p^{m-e}+1\}$ do not exist, where $1\leq e\leq m-1$. Moreover, based on the non-GRS properties of twisted GRS (TGRS) codes, we show that in many cases $e$-Galois self-dual (extended) TGRS codes do not exist. Furthermore, we present a sufficient and necessary condition for $(\ast)$-TGRS codes to be Hermitian self-dual, and then construct several new classes of Hermitian self-dual $(+)$-TGRS and $(\ast)$-TGRS codes.</p></details> | 22 pages |
| **[Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment](http://arxiv.org/abs/2502.13170v2)** | 2025-02-26 | <details><summary>Show</summary><p>The reasoning abilities are one of the most enigmatic and captivating aspects of large language models (LLMs). Numerous studies are dedicated to exploring and expanding the boundaries of this reasoning capability. However, tasks that embody both reasoning and recall characteristics are often overlooked. In this paper, we introduce such a novel task, code reasoning, to provide a new perspective for the reasoning abilities of LLMs. We summarize three meta-benchmarks based on established forms of logical reasoning, and instantiate these into eight specific benchmark tasks. Our testing on these benchmarks reveals that LLMs continue to struggle with identifying satisfactory reasoning pathways. Additionally, we present a new pathway exploration pipeline inspired by human intricate problem-solving methods. This Reflective Hypothesis Decomposition and Amendment (RHDA) pipeline consists of the following iterative steps: (1) Proposing potential hypotheses based on observations and decomposing them; (2) Utilizing tools to validate hypotheses and reflection outcomes; (3) Revising hypothesis in light of observations. Our approach effectively mitigates logical chain collapses arising from forgetting or hallucination issues in multi-step reasoning, resulting in performance gains of up to $3\times$. Finally, we expanded this pipeline by applying it to simulate complex household tasks in real-world scenarios, specifically in VirtualHome, enhancing the handling of failure cases. We release our code and all of results at https://github.com/TnTWoW/code_reasoning.</p></details> | <details><summary>ICLR ...</summary><p>ICLR 2025 Poster;23 pages, 7 figures</p></details> |
| **[Deep-Bench: Deep Learning Benchmark Dataset for Code Generation](http://arxiv.org/abs/2502.18726v1)** | 2025-02-26 | <details><summary>Show</summary><p>Deep learning (DL) has revolutionized areas such as computer vision, natural language processing, and more. However, developing DL systems is challenging due to the complexity of DL workflows. Large Language Models (LLMs), such as GPT, Claude, Llama, Mistral, etc., have emerged as promising tools to assist in DL code generation, offering potential solutions to these challenges. Despite this, existing benchmarks such as DS-1000 are limited, as they primarily focus on small DL code snippets related to pre/post-processing tasks and lack a comprehensive coverage of the full DL pipeline, including different DL phases and input data types. To address this, we introduce DeepBench, a novel benchmark dataset designed for function-level DL code generation. DeepBench categorizes DL problems based on three key aspects: phases such as pre-processing, model construction, and training; tasks, including classification, regression, and recommendation; and input data types such as tabular, image, and text. GPT-4o -- the state-of-the-art LLM -- achieved 31% accuracy on DeepBench, significantly lower than its 60% on DS-1000. We observed similar difficulty for other LLMs (e.g., 28% vs. 54% for Claude, 21% vs. 41% for LLaMA, and 15% vs. 20% for Mistral). This result underscores DeepBench's greater complexity. We also construct a taxonomy of issues and bugs found in LLM-generated DL code, which highlights the distinct challenges that LLMs face when generating DL code compared to general code. Furthermore, our analysis also reveals substantial performance variations across categories, with differences of up to 7% among phases and 37% among tasks. These disparities suggest that DeepBench offers valuable insights into the LLMs' performance and areas for potential improvement in the DL domain.</p></details> |  |
| **[Automated Knowledge Component Generation and Knowledge Tracing for Coding Problems](http://arxiv.org/abs/2502.18632v1)** | 2025-02-25 | <details><summary>Show</summary><p>Knowledge components (KCs) mapped to problems help model student learning, tracking their mastery levels on fine-grained skills thereby facilitating personalized learning and feedback in online learning platforms. However, crafting and tagging KCs to problems, traditionally performed by human domain experts, is highly labor-intensive. We present a fully automated, LLM-based pipeline for KC generation and tagging for open-ended programming problems. We also develop an LLM-based knowledge tracing (KT) framework to leverage these LLM-generated KCs, which we refer to as KCGen-KT. We conduct extensive quantitative and qualitative evaluations validating the effectiveness of KCGen-KT. On a real-world dataset of student code submissions to open-ended programming problems, KCGen-KT outperforms existing KT methods. We investigate the learning curves of generated KCs and show that LLM-generated KCs have a comparable level-of-fit to human-written KCs under the performance factor analysis (PFA) model. We also conduct a human evaluation to show that the KC tagging accuracy of our pipeline is reasonably accurate when compared to that by human domain experts.</p></details> |  |
| **[When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback](http://arxiv.org/abs/2502.18413v1)** | 2025-02-25 | <details><summary>Show</summary><p>Programming is a fundamentally interactive process, yet coding assistants are often evaluated using static benchmarks that fail to measure how well models collaborate with users. We introduce an interactive evaluation pipeline to examine how LLMs incorporate different types of feedback in a collaborative setting. Specifically, we perturb static coding benchmarks so that the code model must interact with a simulated user to retrieve key information about the problem. We find that interaction significantly affects model performance, as the relative rankings of 10 models across 3 datasets often vary between static and interactive settings, despite models being fairly robust to feedback that contains errors. We also observe that even when different feedback types are equally effective with respect to performance, they can impact model behaviors such as (1) how models respond to higher- vs. lower-quality feedback and (2) whether models prioritize aesthetic vs. functional edits. Our work aims to "re-evaluate" model coding capabilities through an interactive lens toward bridging the gap between existing evaluations and real-world usage.</p></details> |  |
| **[How Does Code Pretraining Affect Language Model Task Performance?](http://arxiv.org/abs/2409.04556v2)** | 2025-02-25 | <details><summary>Show</summary><p>Large language models are increasingly trained on corpora containing both natural language and non-linguistic data like source code. Aside from aiding programming-related tasks, anecdotal evidence suggests that including code in pretraining corpora may improve performance on other, unrelated tasks, yet to date no work has been able to establish a causal connection by controlling between language and code data. Here we do just this. We pretrain language models on datasets which interleave natural language and code in two different settings: additive, in which the total volume of data seen during pretraining is held constant; and competitive, in which the volume of language data is held constant. We study how the pretraining mixture affects performance on (a) a diverse collection of tasks included in the BigBench benchmark, and (b) compositionality, measured by generalization accuracy on semantic parsing and syntactic transformations. We find that pretraining on higher proportions of code improves performance on compositional tasks involving structured output (like semantic parsing), and mathematics. Conversely, increase code mixture can harm performance on other tasks, including on tasks that requires sensitivity to linguistic structure such as syntax or morphology, and tasks measuring real-world knowledge.</p></details> |  |
| **[DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis](http://arxiv.org/abs/2502.18297v1)** | 2025-02-25 | <details><summary>Show</summary><p>This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design automation.Our data is available at https://zeju.gitbook.io/lcm-team.</p></details> | 8 pages, 3 figures |
| **[Serializing Java Objects in Plain Code](http://arxiv.org/abs/2405.11294v3)** | 2025-02-25 | <details><summary>Show</summary><p>In managed languages, serialization of objects is typically done in bespoke binary formats such as Protobuf, or markup languages such as XML or JSON. The major limitation of these formats is readability. Human developers cannot read binary code, and in most cases, suffer from the syntax of XML or JSON. This is a major issue when objects are meant to be embedded and read in source code, such as in test cases. To address this problem, we propose plain-code serialization. Our core idea is to serialize objects observed at runtime in the native syntax of a programming language. We realize this vision in the context of Java, and demonstrate a prototype which serializes Java objects to Java source code. The resulting source faithfully reconstructs the objects seen at runtime. Our prototype is called ProDJ and is publicly available. We experiment with ProDJ to successfully plain-code serialize 174,699 objects observed during the execution of 4 open-source Java applications. Our performance measurement shows that the performance impact is not noticeable. Through a user study, we demonstrate that developers prefer plain-code serialized objects within automatically generated tests over their representations as XML or JSON.</p></details> | Under peer-review |
| **[Optimal Communication-Computation Trade-off in Hierarchical Gradient Coding](http://arxiv.org/abs/2502.18251v1)** | 2025-02-25 | <details><summary>Show</summary><p>In this paper, we study gradient coding in a hierarchical setting, where there are intermediate nodes between the server and the workers. This structure reduces the bandwidth requirements at the server, which is a bottleneck in conventional gradient coding systems. In this paper, the intermediate nodes, referred to as $\textit{relays}$, process the data received from workers and send the results to the server for the final gradient computation. Our main contribution is deriving the optimal communication-computation trade-off by designing a linear coding scheme inspired by coded computing techniques, considering straggling and adversarial nodes among both relays and workers. The processing of the data in the relays makes it possible to achieve both the relay-to-server and the worker-to-relay communication loads simultaneously optimal with regard to the computation load.</p></details> | <details><summary>Partl...</summary><p>Partly submitted to ISIT 2025</p></details> |
| **[On the number of minimal and next-to-minimal weight codewords of toric codes over hypersimplices](http://arxiv.org/abs/2502.18084v1)** | 2025-02-25 | <details><summary>Show</summary><p>Toric codes are a type of evaluation code introduced by J.P. Hansen in 2000. They are produced by evaluating (a vector space composed by) polynomials at the points of $(\mathbb{F}_q^*)^s$, the monomials of these polynomials being related to a certain polytope. Toric codes related to hypersimplices are the result of the evaluation of a vector space of homogeneous monomially square-free polynomials of degree $d$. The dimension and minimum distance of toric codes related to hypersimplices have been determined by Jaramillo et al. in 2021. The next-to-minimal weight in the case $d = 1$ has been determined by Jaramillo-Velez et al. in 2023, and has been determined in the cases where $3 \leq d \leq \frac{s - 2}{2}$ or $\frac{s + 2}{2} \leq d < s$, by Carvalho and Patanker in 2024. In this work we characterize and determine the number of minimal (respectively, next-to-minimal) weight codewords when $3 \leq d < s$ (respectively, $3 \leq d \leq \frac{s - 2}{2}$ or $\frac{s + 2}{2} \leq d < s$).</p></details> |  |
| **[Duality of Codes over Non-unital Rings of Order Six](http://arxiv.org/abs/2502.18069v1)** | 2025-02-25 | <details><summary>Show</summary><p>We present some basic theory on the duality of codes over two non-unital rings of order $6$, namely $H_{23}$ and $H_{32}$. For a code $\mathcal{C}$ over these rings, we associate a binary code $\mathcal{C}_a$ and a ternary code $\mathcal{C}_b$. We characterize self-orthogonal, self-dual and quasi self-dual (QSD) codes over these rings using the codes $\mathcal{C}_a$ and $\mathcal{C}_b$. In addition, we present a building-up construction for self-orthogonal codes, introduce cyclic codes and linear complementary dual (LCD) codes. We also gave a classification of self-orthogonal codes for short lengths.</p></details> |  |
| **[LiCoEval: Evaluating LLMs on License Compliance in Code Generation](http://arxiv.org/abs/2408.02487v3)** | 2025-02-25 | <details><summary>Show</summary><p>Recent advances in Large Language Models (LLMs) have revolutionized code generation, leading to widespread adoption of AI coding tools by developers. However, LLMs can generate license-protected code without providing the necessary license information, leading to potential intellectual property violations during software production. This paper addresses the critical, yet underexplored, issue of license compliance in LLM-generated code by establishing a benchmark to evaluate the ability of LLMs to provide accurate license information for their generated code. To establish this benchmark, we conduct an empirical study to identify a reasonable standard for "striking similarity" that excludes the possibility of independent creation, indicating a copy relationship between the LLM output and certain open-source code. Based on this standard, we propose LiCoEval, to evaluate the license compliance capabilities of LLMs, i.e., the ability to provide accurate license or copyright information when they generate code with striking similarity to already existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs, finding that even top-performing LLMs produce a non-negligible proportion (0.88% to 2.01%) of code strikingly similar to existing open-source implementations. Notably, most LLMs fail to provide accurate license information, particularly for code under copyleft licenses. These findings underscore the urgent need to enhance LLM compliance capabilities in code generation tasks. Our study provides a foundation for future research and development to improve license compliance in AI-assisted software development, contributing to both the protection of open-source software copyrights and the mitigation of legal risks for LLM users.</p></details> | <details><summary>The 4...</summary><p>The 47th International Conference on Software Engineering(ICSE 2025)</p></details> |
| **[Teaching Well-Structured Code: A Literature Review of Instructional Approaches](http://arxiv.org/abs/2502.11230v2)** | 2025-02-25 | <details><summary>Show</summary><p>Teaching the software engineers of the future to write high-quality code with good style and structure is important. This systematic literature review identifies existing instructional approaches, their objectives, and the strategies used for measuring their effectiveness. Building on an existing mapping study of code quality in education, we identified 53 papers on code structure instruction. We classified these studies into three categories: (1) studies focused on developing or evaluating automated tools and their usage (e.g., code analyzers, tutors, and refactoring tools), (2) studies discussing other instructional materials, such as learning resources (e.g., refactoring lessons and activities), rubrics, and catalogs of violations, and (3) studies discussing how to integrate code structure into the curriculum through a holistic approach to course design to support code quality. While most approaches use analyzers that point students to problems in their code, incorporating these tools into classrooms is not straightforward. Combined with further research on code structure instruction in the classroom, we call for more studies on effectiveness. Over 40% of instructional studies had no evaluation. Many studies show promise for their interventions by demonstrating improvement in student performance (e.g., reduced violations in student code when using the intervention compared with code that was written without access to the intervention). These interventions warrant further investigation on learning, to see how students apply their knowledge after the instructional supports are removed.</p></details> | <details><summary>Accep...</summary><p>Accepted to the 2025 IEEE/ACM 37th International Conference on Software Engineering Education and Training (CSEE&T)</p></details> |
| **[Scattered Forest Search: Smarter Code Space Exploration with LLMs](http://arxiv.org/abs/2411.05010v2)** | 2025-02-25 | <details><summary>Show</summary><p>We frame code generation as a black-box optimization problem within the code space and demonstrate how optimization-inspired techniques can enhance inference scaling. Based on this perspective, we propose SCATTERED FOREST SEARCH (SFS), a novel approach that improves solution diversity and better exploits feedback during evolutionary search. Our theoretical analysis illustrates how these methods help avoid local optima during optimization, leading to more efficient exploration. Extensive experiments on HumanEval, MBPP, APPS, CodeContests, and Leetcode reveal significant performance gains. For instance, our method achieves a pass@1 rate of 67.1% on HumanEval+ and 87.2% on HumanEval with GPT-3.5, marking improvements of 8.6% and 4.3% over the state-of-the-art, while also halving the iterations needed to find the correct solution. Furthermore, our approach scales more efficiently than existing search techniques, including tree search, line search, and repeated sampling.</p></details> | <details><summary>Accep...</summary><p>Accepted at ICLR 2025 Conference</p></details> |
| **[Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features](http://arxiv.org/abs/2502.17749v1)** | 2025-02-25 | <details><summary>Show</summary><p>Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset LPcode consisting of pairs of human-written code and LLM-paraphrased code using various LLMs. We statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop LPcodedec, a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. LPcodedec outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.</p></details> |  |
| **[Learning to Solve and Verify: A Self-Play Framework for Code and Test Generation](http://arxiv.org/abs/2502.14948v2)** | 2025-02-24 | <details><summary>Show</summary><p>Recent advances in large language models (LLMs) have improved their performance on coding benchmarks. However, improvement is plateauing due to the exhaustion of readily available high-quality data. Prior work has shown the potential of synthetic self-instruct data, but naively training on a model's own outputs can cause error accumulation, especially in coding tasks, where generalization may collapse due to overly simple or erroneous training data, highlighting the need for rigorous quality checks on synthetic data. In this work, we explore an effective approach whereby the model itself verifies the correctness of its own data. We thus propose Sol-Ver, a self-play solver-verifier framework that jointly improves a single model's code and test generation capacity. By iteratively refining code (LLM-as-a-solver) and tests (LLM-as-a-verifier) together, we boost both capabilities without relying on human annotations or larger teacher models. Experiments with the Llama 3.1 8B model demonstrate substantial performance enhancements, achieving average relative improvements of 19.63% in code generation and 17.49% in test generation on MBPP and LiveCodeBench.</p></details> | 13 pages, 5 figures |
| **[Repository-Level Compositional Code Translation and Validation](http://arxiv.org/abs/2410.24117v3)** | 2025-02-24 | <details><summary>Show</summary><p>Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40% of the translated fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 27.03% and 25.14% of fragments. On average, the integrated translation and validation take 34 hours to translate a project, showing its scalability in practice. For the incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.</p></details> |  |
| **[Evaluating the Effectiveness and Efficiency of Demonstration Retrievers in RAG for Coding Tasks](http://arxiv.org/abs/2410.09662v2)** | 2025-02-24 | <details><summary>Show</summary><p>Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating external knowledge bases, achieving state-of-the-art results in various coding tasks. The core of RAG is retrieving demonstration examples, which is essential to balance effectiveness (generation quality) and efficiency (retrieval time) for optimal performance. However, the high-dimensional nature of code representations and large knowledge bases often create efficiency bottlenecks, which are overlooked in previous research. This paper systematically evaluates the efficiency-effectiveness trade-off of retrievers across three coding tasks: Program Synthesis, Commit Message Generation, and Assertion Generation. We examined six retrievers: two sparse (BM25 and BM25L) and four dense retrievers, including one exhaustive dense retriever (SBERT's Semantic Search) and three approximate dense retrievers (ANNOY, LSH, and HNSW). Our findings show that while BM25 excels in effectiveness, it suffers in efficiency as the knowledge base grows beyond 1000 entries. In large-scale retrieval, efficiency differences become more pronounced, with approximate dense retrievers offering the greatest gains. For instance, in Commit Generation task, HNSW achieves a 44x speed up, while only with a 1.74% drop in RougeL compared with BM25. Our results also show that increasing the number of demonstrations in the prompt doesn't always improve the effectiveness and can increase latency and lead to incorrect outputs. Our findings provide valuable insights for practitioners aiming to build efficient and effective RAG systems for coding tasks.</p></details> | <details><summary>11 pa...</summary><p>11 pages, 6 figures, 6 tables, accepted by SANER 2025</p></details> |
| **[DeepSeek-V3, GPT-4, Phi-4, and LLaMA-3.3 generate correct code for LoRaWAN-related engineering tasks](http://arxiv.org/abs/2502.14926v2)** | 2025-02-24 | <details><summary>Show</summary><p>This paper investigates the performance of 16 Large Language Models (LLMs) in automating LoRaWAN-related engineering tasks involving optimal placement of drones and received power calculation under progressively complex zero-shot, natural language prompts. The primary research question is whether lightweight, locally executed LLMs can generate correct Python code for these tasks. To assess this, we compared locally run models against state-of-the-art alternatives, such as GPT-4 and DeepSeek-V3, which served as reference points. By extracting and executing the Python functions generated by each model, we evaluated their outputs on a zero-to-five scale. Results show that while DeepSeek-V3 and GPT-4 consistently provided accurate solutions, certain smaller models-particularly Phi-4 and LLaMA-3.3-also demonstrated strong performance, underscoring the viability of lightweight alternatives. Other models exhibited errors stemming from incomplete understanding or syntactic issues. These findings illustrate the potential of LLM-based approaches for specialized engineering applications while highlighting the need for careful model selection, rigorous prompt design, and targeted domain fine-tuning to achieve reliable outcomes.</p></details> |  |
| **[Encoding and Construction of Quantum Codes from $(γ,Δ)$-cyclic Codes over a Class of Non-chain Rings](http://arxiv.org/abs/2404.01904v2)** | 2025-02-24 | <details><summary>Show</summary><p>Let $\mathbb{F}_q$ be a finite field of $q=p^m$ elements where $p$ is a prime and $m$ is a positive integer. This paper considers $(\gamma,\Delta)$-cyclic codes over a class of finite non-chain commutative rings $\mathscr{R}_{q,s}=\mathbb{F}_q[v_1,v_2,\dots,v_s]/\langle v_i-v_i^2,v_iv_j=v_jv_i=0\rangle$ where $\gamma$ is an automorphism of $\mathscr{R}_{q,s}$, $\Delta$ is a $\gamma$-derivation of $\mathscr{R}_{q,s}$ and $1\leq i\neq j\leq s$ for a positive integer $s$. Here, we show that a $(\gamma,\Delta)$-cyclic code of length $n$ over $\mathscr{R}_{q,s}$ is the direct sum of $(\theta,\Im)$-cyclic codes of length $n$ over $\mathbb{F}_q$, where $\theta$ is an automorphism of $\mathbb{F}_q$ and $\Im$ is a $\theta$-derivation of $\mathbb{F}_q$. Further, necessary and sufficient conditions for both $(\gamma,\Delta)$-cyclic and $(\theta,\Im)$-cyclic codes to contain their Euclidean duals are established. Then, we obtain many quantum codes by applying the dual containing criterion on the Gray images of these codes. These codes have better parameters than those available in the literature. Finally, the encoding and error-correction procedures for our proposed quantum codes are discussed.</p></details> | 24 |
| **[Rethink Delay Doppler Channels and Time-Frequency Coding](http://arxiv.org/abs/2501.00641v3)** | 2025-02-24 | <details><summary>Show</summary><p>In this paper, we rethink delay Doppler channels (also called doubly selective channels). We prove that no modulation schemes (including the current active VOFDM/OTFS) can compensate a non-trivial Doppler spread well. We then discuss some of the existing methods to deal with time-varying channels, in particular time-frequency (TF) coding in an OFDM system. TF coding is equivalent to space-time coding in the math part. We also summarize state of the art on space-time coding that was an active research topic over a decade ago.</p></details> |  |
| **[LogoMotion: Visually-Grounded Code Synthesis for Creating and Editing Animation](http://arxiv.org/abs/2405.07065v2)** | 2025-02-24 | <details><summary>Show</summary><p>Creating animation takes time, effort, and technical expertise. To help novices with animation, we present LogoMotion, an AI code generation approach that helps users create semantically meaningful animation for logos. LogoMotion automatically generates animation code with a method called visually-grounded code synthesis and program repair. This method performs visual analysis, instantiates a design concept, and conducts visual checking to generate animation code. LogoMotion provides novices with code-connected AI editing widgets that help them edit the motion, grouping, and timing of their animation. In a comparison study on 276 animations, LogoMotion was found to produce more content-aware animation than an industry-leading tool. In a user evaluation (n=16) comparing against a prompt-only baseline, these code-connected widgets helped users edit animations with control, iteration, and creative expression.</p></details> |  |
| **[Fundamental Trade-off Between Computation and Communication in Private Coded Distributed Computing](http://arxiv.org/abs/2502.17195v1)** | 2025-02-24 | <details><summary>Show</summary><p>Distributed computing enables scalable machine learning by distributing tasks across multiple nodes, but ensuring privacy in such systems remains a challenge. This paper introduces a private coded distributed computing model that integrates privacy constraints to keep task assignments hidden. By leveraging placement delivery arrays (PDAs), we design an extended PDA framework to characterize achievable computation and communication loads under privacy constraints. By constructing two classes of extended PDAs, we explore the trade-offs between computation and communication, showing that although privacy increases communication overhead, it can be significantly alleviated through optimized PDA-based coded strategies.</p></details> |  |
| **[CodeSwift: Accelerating LLM Inference for Efficient Code Generation](http://arxiv.org/abs/2502.17139v1)** | 2025-02-24 | <details><summary>Show</summary><p>Code generation is a latency-sensitive task that demands high timeliness, but the autoregressive decoding mechanism of Large Language Models (LLMs) leads to poor inference efficiency. Existing LLM inference acceleration methods mainly focus on standalone functions using only built-in components. Moreover, they treat code like natural language sequences, ignoring its unique syntax and semantic characteristics. As a result, the effectiveness of these approaches in code generation tasks remains limited and fails to align with real-world programming scenarios. To alleviate this issue, we propose CodeSwift, a simple yet highly efficient inference acceleration approach specifically designed for code generation, without comprising the quality of the output. CodeSwift constructs a multi-source datastore, providing access to both general and project-specific knowledge, facilitating the retrieval of high-quality draft sequences. Moreover, CodeSwift reduces retrieval cost by controlling retrieval timing, and enhances efficiency through parallel retrieval and a context- and LLM preference-aware cache. Experimental results show that CodeSwift can reach up to 2.53x and 2.54x speedup compared to autoregressive decoding in repository-level and standalone code generation tasks, respectively, outperforming state-of-the-art inference acceleration approaches by up to 88%.</p></details> |  |
| **[MdEval: Massively Multilingual Code Debugging](http://arxiv.org/abs/2411.02310v2)** | 2025-02-24 | <details><summary>Show</summary><p>Code large language models (LLMs) have made significant progress in code debugging by directly generating the correct code based on the buggy code snippet. Programming benchmarks, typically consisting of buggy code snippet and their associated test cases, are used to assess the debugging capabilities of LLMs. However, many existing benchmarks primarily focus on Python and are often limited in terms of language diversity (e.g., DebugBench and DebugEval). To advance the field of multilingual debugging with LLMs, we propose the first massively multilingual debugging benchmark, which includes 3.6K test samples of 18 programming languages and covers the automated program repair (APR) task, the code review (CR) task, and the bug identification (BI) task. Further, we introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs into the correct multilingual queries and solutions (xDebugGen). Further, a multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong baseline specifically to handle the bugs of a wide range of programming languages (e.g. "Missing Mut" in language Rust and "Misused Macro Definition" in language C). Our extensive experiments on MDEVAL reveal a notable performance gap between open-source models and closed-source LLMs (e.g., GPT and Claude series), highlighting huge room for improvement in multilingual code debugging scenarios.</p></details> | 15 pages |
| **[Optimal redundancy of function-correcting codes](http://arxiv.org/abs/2502.16983v1)** | 2025-02-24 | <details><summary>Show</summary><p>Function-correcting codes, introduced by Lenz, Bitar, Wachter-Zeh, and Yaakobi, protect specific function values of a message rather than the entire message. A central challenge is determining the optimal redundancy -- the minimum additional information required to recover function values amid errors. This redundancy depends on both the number of correctable errors $t$ and the structure of message vectors yielding identical function values. While prior works established bounds, key questions remain, such as the optimal redundancy for functions like Hamming weight and Hamming weight distribution, along with efficient code constructions. In this paper, we make the following contributions: (1) For the Hamming weight function, we improve the lower bound on optimal redundancy from $\frac{10(t-1)}{3}$ to $4t - \frac{4}{3}\sqrt{6t+2} + 2$. On the other hand, we provide a systematical approach to constructing explicit FCCs via a novel connection with Gray codes, which also improve the previous upper bound from $\frac{4t-2}{1 - 2\sqrt{\log{2t}/(2t)}}$ to $4t - \log{t}$. Consequently, we almost determine the optimal redundancy for Hamming weight function. (2) The Hamming weight distribution function is defined by the value of Hamming weight divided by a given positive integer $T$. Previous work established that the optimal redundancy is $2t$ when $T > 2t$, while the case $T \le 2t$ remained unclear. We show that the optimal redundancy remains $2t$ when $T \ge t+1$. However, in the surprising regime where $T = o(t)$, we achieve near-optimal redundancy of $4t - o(t)$. Our results reveal a significant distinction in behavior of redundancy for distinct choices of $T$.</p></details> | 17 pages |
| **[Detecting Code Vulnerabilities with Heterogeneous GNN Training](http://arxiv.org/abs/2502.16835v1)** | 2025-02-24 | <details><summary>Show</summary><p>Detecting vulnerabilities in source code is a critical task for software security assurance. Graph Neural Network (GNN) machine learning can be a promising approach by modeling source code as graphs. Early approaches treated code elements uniformly, limiting their capacity to model diverse relationships that contribute to various vulnerabilities. Recent research addresses this limitation by considering the heterogeneity of node types and using Gated Graph Neural Networks (GGNN) to aggregate node information through different edge types. However, these edges primarily function as conduits for passing node information and may not capture detailed characteristics of distinct edge types. This paper presents Inter-Procedural Abstract Graphs (IPAGs) as an efficient, language-agnostic representation of source code, complemented by heterogeneous GNN training for vulnerability prediction. IPAGs capture the structural and contextual properties of code elements and their relationships. We also propose a Heterogeneous Attention GNN (HAGNN) model that incorporates multiple subgraphs capturing different features of source code. These subgraphs are learned separately and combined using a global attention mechanism, followed by a fully connected neural network for final classification. The proposed approach has achieved up to 96.6% accuracy on a large C dataset of 108 vulnerability types and 97.8% on a large Java dataset of 114 vulnerability types, outperforming state-of-the-art methods. Its applications to various real-world software projects have also demonstrated low false positive rates.</p></details> |  |
| **[Code Summarization Beyond Function Level](http://arxiv.org/abs/2502.16704v1)** | 2025-02-23 | <details><summary>Show</summary><p>Code summarization is a critical task in natural language processing and software engineering, which aims to generate concise descriptions of source code. Recent advancements have improved the quality of these summaries, enhancing code readability and maintainability. However, the content of a repository or a class has not been considered in function code summarization. This study investigated the effectiveness of code summarization models beyond the function level, exploring the impact of class and repository contexts on the summary quality. The study involved revising benchmarks for evaluating models at class and repository levels, assessing baseline models, and evaluating LLMs with in-context learning to determine the enhancement of summary quality with additional context. The findings revealed that the fine-tuned state-of-the-art CodeT5+ base model excelled in code summarization, while incorporating few-shot learning and retrieved code chunks from RAG significantly enhanced the performance of LLMs in this task. Notably, the Deepseek Coder 1.3B and Starcoder2 15B models demonstrated substantial improvements in metrics such as BLEURT, METEOR, and BLEU-4 at both class and repository levels. Repository-level summarization exhibited promising potential but necessitates significant computational resources and gains from the inclusion of structured context. Lastly, we employed the recent SIDE code summarization metric in our evaluation. This study contributes to refining strategies for prompt engineering, few-shot learning, and RAG, addressing gaps in benchmarks for code summarization at various levels. Finally, we publish all study details, code, datasets, and results of evaluation in the GitHub repository available at https://github.com/kilimanj4r0/code-summarization-beyond-function-level.</p></details> | <details><summary>Accep...</summary><p>Accepted to LLM4Code @ ICSE'25; 8 pages, 3 figures, 4 tables</p></details> |
| **[SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance](http://arxiv.org/abs/2502.16666v1)** | 2025-02-23 | <details><summary>Show</summary><p>We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. At each step/turn, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to solve it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC's greedy decoding against self-consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.</p></details> | <details><summary>Publi...</summary><p>Published as a full conference paper at ICLR 2025. Shorter(Early) Version accepted at NeurIPS'24 MATH-AI track</p></details> |
| **[Teaching Loop Testing to Young Learners with the Code Critters Mutation Testing Game](http://arxiv.org/abs/2502.16655v1)** | 2025-02-23 | <details><summary>Show</summary><p>Serious games can teach essential coding and testing concepts even to younger audiences. In the Code Critter game critters execute short snippets of block-based code while traversing the game map, and players position magical portals (akin to test oracles) at locations (akin to test inputs) to distinguish between critters executing correct code from those who execute faulty code. However, this adaptation of the tower defense genre limits code under test to basic sequences and branches, and excludes the fundamental programming concept of loops. To address this limitation, in this paper we introduce an entirely new game concept integrated into the Code Critters storyline, tasking players to test the behavior of critters collecting ingredients for a healing potion using loop-based recipes at a second-stage level. In a study involving 29 secondary school students, we observed active engagement with these new loop-integrated levels. The results highlight challenges the students face, which can inform future strategies for improving coding and testing education.</p></details> |  |
| **[CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale](http://arxiv.org/abs/2502.16645v1)** | 2025-02-23 | <details><summary>Show</summary><p>Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync.</p></details> |  |
| **[CodeCriticBench: A Holistic Code Critique Benchmark for Large Language Models](http://arxiv.org/abs/2502.16614v1)** | 2025-02-23 | <details><summary>Show</summary><p>The critique capacity of Large Language Models (LLMs) is essential for reasoning abilities, which can provide necessary suggestions (e.g., detailed analysis and constructive feedback). Therefore, how to evaluate the critique capacity of LLMs has drawn great attention and several critique benchmarks have been proposed. However, existing critique benchmarks usually have the following limitations: (1). Focusing on diverse reasoning tasks in general domains and insufficient evaluation on code tasks (e.g., only covering code generation task), where the difficulty of queries is relatively easy (e.g., the code queries of CriticBench are from Humaneval and MBPP). (2). Lacking comprehensive evaluation from different dimensions. To address these limitations, we introduce a holistic code critique benchmark for LLMs called CodeCriticBench. Specifically, our CodeCriticBench includes two mainstream code tasks (i.e., code generation and code QA) with different difficulties. Besides, the evaluation protocols include basic critique evaluation and advanced critique evaluation for different characteristics, where fine-grained evaluation checklists are well-designed for advanced settings. Finally, we conduct extensive experimental results of existing LLMs, which show the effectiveness of CodeCriticBench.</p></details> |  |
| **[DNA codes from $(\text{\textbaro}, \mathfrak{d}, γ)$-constacyclic codes over $\mathbb{Z}_4+ω\mathbb{Z}_4$](http://arxiv.org/abs/2412.10212v2)** | 2025-02-23 | <details><summary>Show</summary><p>This work introduces a novel approach to constructing DNA codes from linear codes over a non-chain extension of $\mathbb{Z}_4$. We study $(\text{\textbaro},\mathfrak{d}, \gamma)$-constacyclic codes over the ring $\mathfrak{R}=\mathbb{Z}_4+\omega\mathbb{Z}_4, \omega^2=\omega,$ with an $\mathfrak{R}$-automorphism $\text{\textbaro}$ and a $\text{\textbaro}$-derivation $\mathfrak{d}$ over $\mathfrak{R}.$ Further, we determine the generators of the $(\text{\textbaro},\mathfrak{d}, \gamma)$-constacyclic codes over the ring $\mathfrak{R}$ of any arbitrary length and establish the reverse constraint for these codes. Besides the necessary and sufficient criterion to derive reverse-complement codes, we present a construction to obtain DNA codes from these reversible codes. Moreover, we use another construction on the $(\text{\textbaro},\mathfrak{d},\gamma)$-constacyclic codes to generate additional optimal and new classical codes. Finally, we provide several examples of $(\text{\textbaro},\mathfrak{d}, \gamma)$ constacyclic codes and construct DNA codes from established results. The parameters of these linear codes over $\mathbb{Z}_4$ are better and optimal according to the codes available at \cite{z4codes}.</p></details> | 18 |
| **[Some MDS codes over dihedral groups](http://arxiv.org/abs/2502.16590v1)** | 2025-02-23 | <details><summary>Show</summary><p>In this paper,we show some $[2n,2n-2,3]$ and $[2n,2n-3,4]$ MDS codes over dihedral codes $F_qD_{2n}$,in the case $n$ is odd and char$F_q$$\nmid$$\lvert G \rvert$ and $F_q$ contains primitive root of exponent $\lvert G \rvert$ i.e $F_q$ is the splitting field of $G$.Before that,we will give the Wedderburn decomposition and specific forms of linear primitive idempotents of $F_qD_{2n}$ under the above conditions.The MDS codes we construct are obtained by its Wedderburn decomposition and linear primitive idempotents.</p></details> |  |
| **[A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Disjoint Packing](http://arxiv.org/abs/2501.11855v3)** | 2025-02-23 | <details><summary>Show</summary><p>Coded caching is a promising technique to effectively reduce peak traffic by using local caches and the multicast gains generated by these local caches. We prefer to design a coded caching scheme with the subpacketization $F$ and transmission load $R$ as small as possible since these are the key metrics for evaluating the implementation complexity and transmission efficiency of the scheme, respectively. However, most of the existing coded caching schemes have large subpacketizations which grow exponentially with the number of users $K$, and there are a few schemes with linear subpacketizations which have large transmission loads. In this paper, we focus on studying the linear subpacketization, i.e., $K=F$, coded caching scheme with low transmission load. Specifically, we first introduce a new combinatorial structure called non-half-sum disjoint packing (NHSDP) which can be used to generate a coded caching scheme with $K=F$. Then a class of new schemes is obtained by constructing NHSDP. Theoretical and numerical comparisons show that (i) compared to the existing schemes with linear subpacketization (to the number of users), the proposed scheme achieves a lower load; (ii) compared to some existing schemes with polynomial subpacketization, the proposed scheme can also achieve a lower load in some cases; (iii) compared to some existing schemes with exponential subpacketization, the proposed scheme has loads close to those of these schemes in some cases. Moreover, the new concept of NHSDP is closely related to the classical combinatorial structures such as cyclic difference packing (CDP), non-three-term arithmetic progressions (NTAP), and perfect hash family (PHF). These connections indicate that NHSDP is an important combinatorial structure in the field of combinatorial design.</p></details> |  |
| **[A Contemporary Survey on Semantic Communications:Theory of Mind, Generative AI, and Deep Joint Source-Channel Coding](http://arxiv.org/abs/2502.16468v1)** | 2025-02-23 | <details><summary>Show</summary><p>Semantic Communication is becoming the next pillar in wireless communication technology due to its various capabilities. However, it still encounters various challenging obstacles that need to be solved before real-world deployment. The major challenge is the lack of standardization across different directions, leading to variations in interpretations and objectives. In the survey, we provide detailed explanations of three leading directions in semantic communications, namely Theory of Mind, Generative AI, Deep Joint Source-Channel Coding. These directions have been widely studied, developed, and verified by institutes worldwide, and their effectiveness has increased along with the advancement in technology. We first introduce the concepts and background of these directions. Firstly, we introduce the Theory of Mind, where the communication agents interact with each other, gaining understanding from observations and slowly forming a common language. Secondly, we present generative AI models, which can create new content and offer more freedom to interpret the data beyond the limitation of semantic meaning compression of raw data before transmitting it. The received signal is then decoded by another generative AI model to execute the oriented task. Thirdly, we review deep learning models to jointly optimize the source and channel coding modules. Then, we present a comprehensive survey of existing works in each direction, thereby offering readers an overview of past achievements and potential avenues for further contribution. Moreover, for each direction, we identify and discuss the existing challenges that must be addressed before these approaches can be effectively deployed in real-world scenarios.</p></details> | <details><summary>34 pa...</summary><p>34 pages, 9 figures, 7 tables</p></details> |
| **[Beyond Trusting Trust: Multi-Model Validation for Robust Code Generation](http://arxiv.org/abs/2502.16279v1)** | 2025-02-22 | <details><summary>Show</summary><p>This paper explores the parallels between Thompson's "Reflections on Trusting Trust" and modern challenges in LLM-based code generation. We examine how Thompson's insights about compiler backdoors take on new relevance in the era of large language models, where the mechanisms for potential exploitation are even more opaque and difficult to analyze. Building on this analogy, we discuss how the statistical nature of LLMs creates novel security challenges in code generation pipelines. As a potential direction forward, we propose an ensemble-based validation approach that leverages multiple independent models to detect anomalous code patterns through cross-model consensus. This perspective piece aims to spark discussion about trust and validation in AI-assisted software development.</p></details> | 3 pages, 2 figures |
| **[Practical programming research of Linear DML model based on the simplest Python code: From the standpoint of novice researchers](http://arxiv.org/abs/2502.16172v1)** | 2025-02-22 | <details><summary>Show</summary><p>This paper presents linear DML models for causal inference using the simplest Python code on a Jupyter notebook based on an Anaconda platform and compares the performance of different DML models. The results show that current Library API technology is not yet sufficient to enable novice Python users to build qualified and high-quality DML models with the simplest coding approach. Novice users attempting to perform DML causal inference using Python still have to improve their mathematical and computer knowledge to adapt to more flexible DML programming. Additionally, the issue of mismatched outcome variable dimensions is also widespread when building linear DML models in Jupyter notebook.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 4 tables, 3 figures</p></details> |
| **[Efficient Approximate Degenerate Ordered Statistics Decoding for Quantum Codes via Reliable Subset Reduction](http://arxiv.org/abs/2412.21118v2)** | 2025-02-22 | <details><summary>Show</summary><p>Efficient decoding of quantum codes is crucial for achieving high-performance quantum error correction. In this paper, we introduce the concept of approximate degenerate decoding and integrate it with ordered statistics decoding (OSD). Previously, we proposed a reliability metric that leverages both hard and soft decisions from the output of belief propagation (BP), which is particularly useful for identifying highly reliable subsets of variables. Using the approach of reliable subset reduction, we reduce the effective problem size. Additionally, we identify a degeneracy condition that allows high-order OSD to be simplified to order-0 OSD. By integrating these techniques, we present an ADOSD algorithm that significantly improves OSD efficiency in the code capacity noise model. We demonstrate the effectiveness of our BP+ADOSD approach through extensive simulations on a varity of quantum codes, including generalized hypergraph-product codes, topological codes, lift-connected surface codes, and bivariate bicycle codes. The results indicate that the BP+ADOSD decoder outperforms existing methods, achieving higher error thresholds and enhanced performance at low error rates. Additionally, we validate the efficiency of our approach in terms of computational time, demonstrating that ADOSD requires, on average, the same amount of time as two to three BP iterations on surface codes at a depolarizing error rate of around $1\%$. All the proposed algorithms are compared using single-threaded CPU implementations.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 10 figures, 5 tables</p></details> |
| **[ChangeGuard: Validating Code Changes via Pairwise Learning-Guided Execution](http://arxiv.org/abs/2410.16092v2)** | 2025-02-22 | <details><summary>Show</summary><p>Code changes are an integral part of the software development process. Many code changes are meant to improve the code without changing its functional behavior, e.g., refactorings and performance improvements. Unfortunately, validating whether a code change preserves the behavior is non-trivial, particularly when the code change is performed deep inside a complex project. This paper presents ChangeGuard, an approach that uses learning-guided execution to compare the runtime behavior of a modified function. The approach is enabled by the novel concept of pairwise learning-guided execution and by a set of techniques that improve the robustness and coverage of the state-of-the-art learning-guided execution technique. Our evaluation applies ChangeGuard to a dataset of 224 manually annotated code changes from popular Python open-source projects and to three datasets of code changes obtained by applying automated code transformations. Our results show that the approach identifies semantics-changing code changes with a precision of 77.1% and a recall of 69.5%, and that it detects unexpected behavioral changes introduced by automatic code refactoring tools. In contrast, the existing regression tests of the analyzed projects miss the vast majority of semantics-changing code changes, with a recall of only 7.6%. We envision our approach being useful for detecting unintended behavioral changes early in the development process and for improving the quality of automated code transformations.</p></details> | <details><summary>Accep...</summary><p>Accepted at ACM International Conference on the Foundations of Software Engineering (FSE) 2025</p></details> |
| **[InterLink: Linking Text with Code and Output in Computational Notebooks](http://arxiv.org/abs/2502.16114v1)** | 2025-02-22 | <details><summary>Show</summary><p>Computational notebooks, widely used for ad-hoc analysis and often shared with others, can be difficult to understand because the standard linear layout is not optimized for reading. In particular, related text, code, and outputs may be spread across the UI making it difficult to draw connections. In response, we introduce InterLink, a plugin designed to present the relationships between text, code, and outputs, thereby making notebooks easier to understand. In a formative study, we identify pain points and derive design requirements for identifying and navigating relationships among various pieces of information within notebooks. Based on these requirements, InterLink features a new layout that separates text from code and outputs into two columns. It uses visual links to signal relationships between text and associated code and outputs and offers interactions for navigating related pieces of information. In a user study with 12 participants, those using InterLink were 13.6% more accurate at finding and integrating information from complex analyses in computational notebooks. These results show the potential of notebook layouts that make them easier to understand.</p></details> | <details><summary>Accep...</summary><p>Accepted at CHI Conference on Human Factors in Computing Systems (CHI'25), April 26-May 1, 2025, Yokohama, Japan</p></details> |
| **[WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs](http://arxiv.org/abs/2404.06369v2)** | 2025-02-22 | <details><summary>Show</summary><p>Automatically generating webpage code from webpage designs can significantly reduce the workload of front-end developers, and recent Multimodal Large Language Models (MLLMs) have shown promising potential in this area. However, our investigation reveals that most existing MLLMs are constrained by the absence of high-quality, large-scale, real-world datasets, resulting in inadequate performance in automated webpage code generation. To fill this gap, this paper introduces WebCode2M, a new dataset comprising 2.56 million instances, each containing a design image along with the corresponding webpage code and layout details. Sourced from real-world web resources, WebCode2M offers a rich and valuable dataset for webpage code generation across a variety of applications. The dataset quality is ensured by a scoring model that filters out instances with aesthetic deficiencies or other incomplete elements. To validate the effectiveness of WebCode2M, we introduce a baseline model based on the Vision Transformer (ViT), named WebCoder, and establish a benchmark for fair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure the structural hierarchy recall. The benchmarking results demonstrate that our dataset significantly improves the ability of MLLMs to generate code from webpage designs, confirming its effectiveness and usability for future applications in front-end design tools. Finally, we highlight several practical challenges introduced by our dataset, calling for further research. The code and dataset are publicly available at our project homepage: https://webcode2m.github.io.</p></details> | WWW'25 |
| **[Accountability in Code Review: The Role of Intrinsic Drivers and the Impact of LLMs](http://arxiv.org/abs/2502.15963v1)** | 2025-02-21 | <details><summary>Show</summary><p>Accountability is an innate part of social systems. It maintains stability and ensures positive pressure on individuals' decision-making. As actors in a social system, software developers are accountable to their team and organization for their decisions. However, the drivers of accountability and how it changes behavior in software development are less understood. In this study, we look at how the social aspects of code review affect software engineers' sense of accountability for code quality. Since software engineering (SE) is increasingly involving Large Language Models (LLM) assistance, we also evaluate the impact on accountability when introducing LLM-assisted code reviews. We carried out a two-phased sequential qualitative study (interviews -> focus groups). In Phase I (16 interviews), we sought to investigate the intrinsic drivers of software engineers influencing their sense of accountability for code quality, relying on self-reported claims. In Phase II, we tested these traits in a more natural setting by simulating traditional peer-led reviews with focus groups and then LLM-assisted review sessions. We found that there are four key intrinsic drivers of accountability for code quality: personal standards, professional integrity, pride in code quality, and maintaining one's reputation. In a traditional peer-led review, we observed a transition from individual to collective accountability when code reviews are initiated. We also found that the introduction of LLM-assisted reviews disrupts this accountability process, challenging the reciprocity of accountability taking place in peer-led evaluations, i.e., one cannot be accountable to an LLM. Our findings imply that the introduction of AI into SE must preserve social integrity and collective accountability mechanisms.</p></details> | <details><summary>45 pa...</summary><p>45 pages; accepted at ACM TOSEM 2025</p></details> |
| **[MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use](http://arxiv.org/abs/2502.15872v1)** | 2025-02-21 | <details><summary>Show</summary><p>When a human requests an LLM to complete a coding task using functionality from a large code repository, how do we provide context from the repo to the LLM? One approach is to add the entire repo to the LLM's context window. However, most tasks involve only fraction of symbols from a repo, longer contexts are detrimental to the LLM's reasoning abilities, and context windows are not unlimited. Alternatively, we could emulate the human ability to navigate a large repo, pick out the right functionality, and form a plan to solve the task. We propose MutaGReP (Mutation-guided Grounded Repository Plan Search), an approach to search for plans that decompose a user request into natural language steps grounded in the codebase. MutaGReP performs neural tree search in plan space, exploring by mutating plans and using a symbol retriever for grounding. On the challenging LongCodeArena benchmark, our plans use less than 5% of the 128K context window for GPT-4o but rival the coding performance of GPT-4o with a context window filled with the repo. Plans produced by MutaGReP allow Qwen 2.5 Coder 32B and 72B to match the performance of GPT-4o with full repo context and enable progress on the hardest LongCodeArena tasks. Project page: zaidkhan.me/MutaGReP</p></details> | <details><summary>Proje...</summary><p>Project page: zaidkhan.me/MutaGReP</p></details> |
| **[List Decoding Quotient Reed-Muller Codes](http://arxiv.org/abs/2502.15650v1)** | 2025-02-21 | <details><summary>Show</summary><p>Reed-Muller codes consist of evaluations of $n$-variate polynomials over a finite field $\mathbb{F}$ with degree at most $d$. Much like every linear code, Reed-Muller codes can be characterized by constraints, where a codeword is valid if and only if it satisfies all \emph{degree-$d$} constraints. For a subset $\tilde{X} \subseteq \mathbb{F}^n$, we introduce the notion of \emph{$\tilde{X}$-quotient} Reed-Muller code. A function $F : \tilde{X} \rightarrow \mathbb{F}$ is a valid codeword in the quotient code if it satisfies all the constraints of degree-$d$ polynomials \emph{lying in $\tilde{X}$}. This gives rise to a novel phenomenon: a quotient codeword may have \emph{many} extensions to original codewords. This weakens the connection between original codewords and quotient codewords which introduces a richer range of behaviors along with substantial new challenges. Our goal is to answer the following question: what properties of $\tilde{X}$ will imply that the quotient code inherits its distance and list-decoding radius from the original code? We address this question using techniques developed by Bhowmick and Lovett [BL14], identifying key properties of $\mathbb{F}^n$ used in their proof and extending them to general subsets $\tilde{X} \subseteq \mathbb{F}^n$. By introducing a new tool, we overcome the novel challenge in analyzing the quotient code that arises from the weak connection between original and quotient codewords. This enables us to apply known results from additive combinatorics and algebraic geometry [KZ18, KZ19, LZ21] to show that when $\tilde{X}$ is a \emph{high rank variety}, $\tilde{X}$-quotient Reed-Muller codes inherit the distance and list-decoding parameters from the original Reed-Muller codes.</p></details> |  |
| **[Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](http://arxiv.org/abs/2502.13311v2)** | 2025-02-21 | <details><summary>Show</summary><p>Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized guidance in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To address this limitation, in this work, we focus on coding tutoring, a challenging problem that requires tutors to proactively guide students toward completing predefined coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER), which combines knowledge tracing to estimate a student's knowledge state and turn-by-turn verification to ensure effective guidance toward task completion. We introduce DICT, an automatic evaluation protocol that assesses tutor agents holistically using controlled student simulation and code generation tests. Extensive experiments reveal the challenges of coding tutoring and demonstrate that TRAVER achieves a significantly higher success rate. Although we use code tutoring as an example in this paper, our results and findings can be extended beyond coding, providing valuable insights into advancing tutoring agents for a variety of tasks.</p></details> |  |
| **[Programmers Aren't Obsolete Yet: A Syllabus for Teaching CS Students to Responsibly Use Large Language Models for Code Generation](http://arxiv.org/abs/2502.15493v1)** | 2025-02-21 | <details><summary>Show</summary><p>Large Language Models (LLMs) have emerged as powerful tools for automating code generation, offering immense potential to enhance programmer productivity. However, their non-deterministic nature and reliance on user input necessitate a robust understanding of programming fundamentals to ensure their responsible and effective use. In this paper, we argue that foundational computing skills remain crucial in the age of LLMs. We propose a syllabus focused on equipping computer science students to responsibly embrace LLMs as performance enhancement tools. This work contributes to the discussion on the why, when, and how of integrating LLMs into computing education, aiming to better prepare programmers to leverage these tools without compromising foundational software development principles.</p></details> | <details><summary>This ...</summary><p>This is the author's version of the work. It is posted here for your personal use. Not for redistribution</p></details> |
| **[Spatially-Coupled QLDPC Codes](http://arxiv.org/abs/2305.00137v5)** | 2025-02-21 | <details><summary>Show</summary><p>Spatially-coupled (SC) codes is a class of convolutional LDPC codes that has been well investigated in classical coding theory thanks to their high performance and compatibility with low-latency decoders. We describe toric codes as quantum counterparts of classical two-dimensional spatially-coupled (2D-SC) codes, and introduce spatially-coupled quantum LDPC (SC-QLDPC) codes as a generalization. We use the convolutional structure to represent the parity check matrix of a 2D-SC code as a polynomial in two indeterminates, and derive an algebraic condition that is both necessary and sufficient for a 2D-SC code to be a stabilizer code. This algebraic framework facilitates the construction of new code families. While not the focus of this paper, we note that small memory facilitates physical connectivity of qubits, and it enables local encoding and low-latency windowed decoding. In this paper, we use the algebraic framework to optimize short cycles in the Tanner graph of 2D-SC hypergraph product (HGP) codes that arise from short cycles in either component code. While prior work focuses on QLDPC codes with rate less than 1/10, we construct 2D-SC HGP codes with small memories, higher rates (about 1/3), and superior thresholds.</p></details> | <details><summary>36 pa...</summary><p>36 pages, 10 figures. Title corrected from 'QDLPC' to 'QLDPC'</p></details> |
| **[Decoding for Punctured Convolutional and Turbo Codes: A Deep Learning Solution for Protocols Compliance](http://arxiv.org/abs/2502.15475v1)** | 2025-02-21 | <details><summary>Show</summary><p>Neural network-based decoding methods have shown promise in enhancing error correction performance, but traditional approaches struggle with the challenges posed by punctured codes. In particular, these methods fail to address the complexities of variable code rates and the need for protocol compatibility. This paper presents a unified Long Short-Term Memory (LSTM)-based decoding architecture specifically designed to overcome these challenges. The proposed method unifies punctured convolutional and Turbo codes. A puncture embedding mechanism integrates puncturing patterns directly into the network, enabling seamless adaptation to varying code rates, while balanced bit error rate training ensures robustness across different code lengths, rates, and channels, maintaining protocol flexibility. Extensive simulations in Additive White Gaussian Noise and Rayleigh fading channels demonstrate that the proposed approach outperforms conventional decoding techniques, providing significant improvements in decoding accuracy and robustness. These results underscore the potential of LSTM-based decoding as a promising solution for next-generation artificial intelligence powered communication systems.</p></details> |  |
| **[Demystifying 5G Polar and LDPC Codes: A Comprehensive Review and Foundations](http://arxiv.org/abs/2502.11053v2)** | 2025-02-21 | <details><summary>Show</summary><p>This paper serves as a comprehensive guide for practitioners and scholars aiming to understand the channel coding and decoding schemes integral to the 5G NR standard, with a particular focus on LDPC and polar codes. We start by explaining the design procedures that underlie these channel codes, offering fundamental information from the perspectives of both encoding and decoding. In order to determine the present status of research in this area, we also provide a thorough literature review. Notably, we add comprehensive, standard-specific information to these foundational evaluations that is frequently difficult to extract from technical specification documents. The significance of reviewing and refining the foundations of the aforementioned codes lies in their potential to serve as candidate error-correcting codes for the future 6G standard and beyond.</p></details> |  |
| **[Comparative Analysis of Large Language Models for Context-Aware Code Completion using SAFIM Framework](http://arxiv.org/abs/2502.15243v1)** | 2025-02-21 | <details><summary>Show</summary><p>The advent of Large Language Models (LLMs) has revolutionized code completion, transforming it into a more intelligent and context-aware feature in modern integrated development environments. These advancements have significantly enhanced developers' ability to write efficient and error-free code. This study evaluates the performance of several chat-based LLMs, including Gemini 1.5 Flash, Gemini 1.5 Pro, GPT-4o, GPT-4o-mini, and GPT-4 Turbo, using the Syntax-Aware Fill-in-the-Middle (SAFIM) dataset. This benchmark is specifically designed to assess models' capabilities in syntax-sensitive code generation. Performance metrics, such as cosine similarity with ground-truth completions and latency, were employed to measure both accuracy and efficiency. The findings reveal substantial differences in the models' code completion abilities, offering valuable insights into their respective strengths and weaknesses. This work provides a comparative analysis that underscores the trade-offs between accuracy and speed, establishing a benchmark for future advancements in LLM-based code completion.</p></details> | 9 pages |
| **[Measuring AI agent autonomy: Towards a scalable approach with code inspection](http://arxiv.org/abs/2502.15212v1)** | 2025-02-21 | <details><summary>Show</summary><p>AI agents are AI systems that can achieve complex goals autonomously. Assessing the level of agent autonomy is crucial for understanding both their potential benefits and risks. Current assessments of autonomy often focus on specific risks and rely on run-time evaluations -- observations of agent actions during operation. We introduce a code-based assessment of autonomy that eliminates the need to run an AI agent to perform specific tasks, thereby reducing the costs and risks associated with run-time evaluations. Using this code-based framework, the orchestration code used to run an AI agent can be scored according to a taxonomy that assesses attributes of autonomy: impact and oversight. We demonstrate this approach with the AutoGen framework and select applications.</p></details> | <details><summary>NeurI...</summary><p>NeurIPS Socially Responsible Language Modelling Research (SoLaR) Workshop 2024</p></details> |
| **[GNN-Coder: Boosting Semantic Code Retrieval with Combined GNNs and Transformer](http://arxiv.org/abs/2502.15202v1)** | 2025-02-21 | <details><summary>Show</summary><p>Code retrieval is a crucial component in modern software development, particularly in large-scale projects. However, existing approaches relying on sequence-based models often fail to fully exploit the structural dependencies inherent in code, leading to suboptimal retrieval performance, particularly with structurally complex code fragments. In this paper, we introduce GNN-Coder, a novel framework based on Graph Neural Network (GNN) to utilize Abstract Syntax Tree (AST). We make the first attempt to study how GNN-integrated Transformer can promote the development of semantic retrieval tasks by capturing the structural and semantic features of code. We further propose an innovative graph pooling method tailored for AST, utilizing the number of child nodes as a key feature to highlight the intrinsic topological relationships within the AST. This design effectively integrates both sequential and hierarchical representations, enhancing the model's ability to capture code structure and semantics. Additionally, we introduce the Mean Angular Margin (MAM), a novel metric for quantifying the uniformity of code embedding distributions, providing a standardized measure of feature separability. The proposed method achieves a lower MAM, indicating a more discriminative feature representation. This underscores GNN-Coder's superior ability to distinguish between code snippets, thereby enhancing retrieval accuracy. Experimental results show that GNN-Coder significantly boosts retrieval performance, with a 1\%-10\% improvement in MRR on the CSN dataset, and a notable 20\% gain in zero-shot performance on the CosQA dataset.</p></details> |  |
| **[Selective Prompt Anchoring for Code Generation](http://arxiv.org/abs/2408.09121v4)** | 2025-02-21 | <details><summary>Show</summary><p>Recent advances in large language models (LLMs) have transformed software development by automatically generating code from natural language. Yet challenges remain in generating fully correct code that aligns with user intent. Our study reveals that LLMs tend to pay less attention to user prompts as more code tokens are generated. We hypothesize that this attention dilution issue is an important reason for code generation errors. To mitigate this issue, we propose Selective Prompt Anchoring (SPA) to guide code LLMs to pay more attention to user intent when generating code. We evaluate SPA using six base LLMs across six benchmarks. Our results demonstrate that SPA enhances Pass@1 by up to 12.9%, consistently outperforming SOTA code generation methods in all settings. Our code is available at https://github.com/magic-YuanTian/Selective-Prompt-Anchoring.</p></details> |  |
| **[Mechanistic Understanding of Language Models in Syntactic Code Completion](http://arxiv.org/abs/2502.18499v1)** | 2025-02-20 | <details><summary>Show</summary><p>Recently, language models (LMs) have shown impressive proficiency in code generation tasks, especially when fine-tuned on code-specific datasets, commonly known as Code LMs. However, our understanding of the internal decision-making processes of Code LMs, such as how they use their (syntactic or semantic) knowledge, remains limited, which could lead to unintended harm as they are increasingly used in real life. This motivates us to conduct one of the first Mechanistic Interpretability works to understand how Code LMs perform a syntactic completion task, specifically the closing parenthesis task, on the CodeLlama-7b model (Roziere et al. 2023). Our findings reveal that the model requires middle-later layers until it can confidently predict the correct label for the closing parenthesis task. Additionally, we identify that while both multi-head attention (MHA) and feed-forward (FF) sub-layers play essential roles, MHA is particularly crucial. Furthermore, we also discover attention heads that keep track of the number of already closed parentheses precisely but may or may not promote a correct number of closing parentheses that are still missing, leading to a positive or negative impact on the model's performance.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 4 figures, accepted to the AAAI 2025 Workshop on Towards Knowledgeable Foundation Models</p></details> |

## Program
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Programming Really Is Simple Mathematics](http://arxiv.org/abs/2502.17149v3)** | 2025-02-27 | <details><summary>Show</summary><p>A re-construction of the fundamentals of programming as a small mathematical theory (PRISM) based on elementary set theory. Highlights: $\bullet$ Zero axioms. No properties are assumed, all are proved (from standard set theory). $\bullet$ A single concept covers specifications and programs. $\bullet$ Its definition only involves one relation and one set. $\bullet$ Everything proceeds from three operations: choice, composition and restriction. $\bullet$ These techniques suffice to derive the axioms of classic papers on the "laws of programming" as consequences and prove them mechanically. $\bullet$ The ordinary subset operator suffices to define both the notion of program correctness and the concepts of specialization and refinement. $\bullet$ From this basis, the theory deduces dozens of theorems characterizing important properties of programs and programming. $\bullet$ All these theorems have been mechanically verified (using Isabelle/HOL); the proofs are available in a public repository. This paper is a considerable extension and rewrite of an earlier contribution [arXiv:1507.00723]</p></details> |  |
| **[LangProBe: a Language Programs Benchmark](http://arxiv.org/abs/2502.20315v1)** | 2025-02-27 | <details><summary>Show</summary><p>Composing language models (LMs) into multi-step language programs and automatically optimizing their modular prompts is now a mainstream paradigm for building AI systems, but the tradeoffs in this space have only scarcely been studied before. We introduce LangProBe, the first large-scale benchmark for evaluating the architectures and optimization strategies for language programs, with over 2000 combinations of tasks, architectures, optimizers, and choices of LMs. Using LangProBe, we are the first to study the impact of program architectures and optimizers (and their compositions together and with different models) on tradeoffs of quality and cost. We find that optimized language programs offer strong cost--quality Pareto improvement over raw calls to models, but simultaneously demonstrate that human judgment (or empirical decisions) about which compositions to pursue is still necessary for best performance. We will open source the code and evaluation data for LangProBe.</p></details> |  |
| **[Bugfix: a standard language, database schema and repository for research on bugs and automatic program repair](http://arxiv.org/abs/2502.15599v2)** | 2025-02-27 | <details><summary>Show</summary><p>Automatic Program Repair (APR) is a brilliant idea: when detecting a bug, also provide suggestions for correcting the program. Progress towards that goal is hindered by the absence of a common frame of reference for the multiplicity of APR ideas, methods, tools, programming languages and environments. Bugfix is an effort at providing such a framework: a standardized set of notations, tools and interfaces, as well as a database of bugs and fixes, for use by the APR research community to try out ideas and compare results. The most directly visible component of the Bugfix effort is the Bugfix language, a human-readable formalism making it possible to describe elements of the following kinds: a bug (described abstractly, for example the permutation of two arguments in a call); a bug example (an actual occurrence of a bug, in a specific code written in a specific programming language, and usually recorded in some repository); a fix (a particular correction of a bug, obtained for example by reversing the misplaced arguments); an application (an entity that demonstrates how a actual code example matches with a fix); a construct (the abstract description of a programming mechanism, for example a ``while'' loop, independently of its realization in a programming language; and a language (a description of how a particular programming language includes certain constructs and provides specific concrete syntax for each of them -- for example Java includes loop, assignment etc. and has a defined format for each of them). A JSON API provides it in a form accessible to tools. Bugfix includes a repository containing a considerable amount of bugs, examples and fixes. Note: An early step towards this article was a short contribution (Ref [1]) to the 2024 ICSE. The present text reuses a few elements of introduction and motivation but is otherwise thoroughly reworked and extended.</p></details> |  |
| **[Program Synthesis Dialog Agents for Interactive Decision-Making](http://arxiv.org/abs/2502.19610v1)** | 2025-02-26 | <details><summary>Show</summary><p>Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns.</p></details> |  |
| **[Multi-Language Probabilistic Programming](http://arxiv.org/abs/2502.19538v1)** | 2025-02-26 | <details><summary>Show</summary><p>There are many different probabilistic programming languages that are specialized to specific kinds of probabilistic programs. From a usability and scalability perspective, this is undesirable: today, probabilistic programmers are forced up-front to decide which language they want to use and cannot mix-and-match different languages for handling heterogeneous programs. To rectify this, we seek a foundation for sound interoperability for probabilistic programming languages: just as today's Python programmers can resort to low-level C programming for performance, we argue that probabilistic programmers should be able to freely mix different languages for meeting the demands of heterogeneous probabilistic programming environments. As a first step towards this goal, we introduce \textsc{MultiPPL}, a probabilistic multi-language that enables programmers to interoperate between two different probabilistic programming languages: one that leverages a high-performance exact discrete inference strategy, and one that uses approximate importance sampling. We give a syntax and semantics for \textsc{MultiPPL}, prove soundness of its inference algorithm, and provide empirical evidence that it enables programmers to perform inference on complex heterogeneous probabilistic programs and flexibly exploits the strengths and weaknesses of two languages simultaneously.%</p></details> | <details><summary>Accep...</summary><p>Accepted for publication at OOPSLA 2025 (R1)</p></details> |
| **[Verde: Verification via Refereed Delegation for Machine Learning Programs](http://arxiv.org/abs/2502.19405v1)** | 2025-02-26 | <details><summary>Show</summary><p>Machine learning programs, such as those performing inference, fine-tuning, and training of LLMs, are commonly delegated to untrusted compute providers. To provide correctness guarantees for the client, we propose adapting the cryptographic notion of refereed delegation to the machine learning setting. This approach enables a computationally limited client to delegate a program to multiple untrusted compute providers, with a guarantee of obtaining the correct result if at least one of them is honest. Refereed delegation of ML programs poses two technical hurdles: (1) an arbitration protocol to resolve disputes when compute providers disagree on the output, and (2) the ability to bitwise reproduce ML programs across different hardware setups, For (1), we design Verde, a dispute arbitration protocol that efficiently handles the large scale and graph-based computational model of modern ML programs. For (2), we build RepOps (Reproducible Operators), a library that eliminates hardware "non-determinism" by controlling the order of floating point operations performed on all hardware. Our implementation shows that refereed delegation achieves both strong guarantees for clients and practical overheads for compute providers.</p></details> |  |
| **[Foundations for Deductive Verification of Continuous Probabilistic Programs: From Lebesgue to Riemann and Back](http://arxiv.org/abs/2502.19388v1)** | 2025-02-26 | <details><summary>Show</summary><p>We lay out novel foundations for the computer-aided verification of guaranteed bounds on expected outcomes of imperative probabilistic programs featuring (i) general loops, (ii) continuous distributions, and (iii) conditioning. To handle loops we rely on user-provided quantitative invariants, as is well established. However, in the realm of continuous distributions, invariant verification becomes extremely challenging due to the presence of integrals in expectation-based program semantics. Our key idea is to soundly under- or over-approximate these integrals via Riemann sums. We show that this approach enables the SMT-based invariant verification for programs with a fairly general control flow structure. On the theoretical side, we prove convergence of our Riemann approximations, and establish coRE-completeness of the central verification problems. On the practical side, we show that our approach enables to use existing automated verifiers targeting discrete probabilistic programs for the verification of programs involving continuous sampling. Towards this end, we implement our approach in the recent quantitative verification infrastructure Caesar by encoding Riemann sums in its intermediate verification language. We present several promising case studies.</p></details> | <details><summary>Full ...</summary><p>Full version of OOPSLA 25 paper, 55 pages</p></details> |
| **[Embodying mechano-fluidic memory in soft machines to program behaviors upon interactions](http://arxiv.org/abs/2502.19192v1)** | 2025-02-26 | <details><summary>Show</summary><p>Soft machines display shape adaptation to external circumstances due to their intrinsic compliance. To achieve increasingly more responsive behaviors upon interactions without relying on centralized computation, embodying memory directly in the machines' structure is crucial. Here, we harness the bistability of elastic shells to alter the fluidic properties of an enclosed cavity, thereby switching between stable frequency states of a locomoting self-oscillating machine. To program these memory states upon interactions, we develop fluidic circuits surrounding the bistable shell, with soft tubes that kink and unkink when externally touched. We implement circuits for both long-term and short-term memory in a soft machine that switches behaviors in response to a human user and that autonomously changes direction after detecting a wall. By harnessing only geometry and elasticity, embodying memory allows physical structures without a central brain to exhibit autonomous feats that are typically reserved for computer-based robotic systems.</p></details> |  |
| **[DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition](http://arxiv.org/abs/2502.19133v1)** | 2025-02-26 | <details><summary>Show</summary><p>Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners' decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners' personalized construction of a step tree through a "learner-LLM co-decomposition" approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox's impact on cognitive load, identified usage patterns, and analyzed learners' strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.</p></details> |  |
| **[Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support](http://arxiv.org/abs/2502.18658v1)** | 2025-02-25 | <details><summary>Show</summary><p>AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and \revise{interaction context support} alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.</p></details> |  |
| **[Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments](http://arxiv.org/abs/2502.17956v1)** | 2025-02-25 | <details><summary>Show</summary><p>Multi-step reasoning is essential for large language models (LLMs), yet multilingual performance remains challenging. While Chain-of-Thought (CoT) prompting improves reasoning, it struggles with non-English languages due to the entanglement of reasoning and execution. Program-of-Thought (PoT) prompting separates reasoning from execution, offering a promising alternative but shifting the challenge to generating programs from non-English questions. We propose a framework to evaluate PoT by separating multilingual reasoning from code execution to examine (i) the impact of fine-tuning on question-reasoning alignment and (ii) how reasoning quality affects answer correctness. Our findings demonstrate that PoT fine-tuning substantially enhances multilingual reasoning, outperforming CoT fine-tuned models. We further demonstrate a strong correlation between reasoning quality (measured through code quality) and answer accuracy, highlighting its potential as a test-time performance improvement heuristic.</p></details> |  |
| **[The AI Definition and a Program Which Satisfies this Definition](http://arxiv.org/abs/2212.03184v2)** | 2025-02-25 | <details><summary>Show</summary><p>We will consider all policies of the agent and will prove that one of them is the best performing policy. While that policy is not computable, computable policies do exist in its proximity. We will define AI as a computable policy which is sufficiently proximal to the best performing policy. Before we can define the agent's best performing policy, we need a language for description of the world. We will also use this language to develop a program which satisfies the AI definition. The program will first understand the world by describing it in the selected language. The program will then use the description in order to predict the future and select the best possible move. While this program is extremely inefficient and practically unusable, it can be improved by refining both the language for description of the world and the algorithm used to predict the future. This can yield a program which is both efficient and consistent with the AI definition.</p></details> |  |
| **[SpecGen: Automated Generation of Formal Program Specifications via Large Language Models](http://arxiv.org/abs/2401.08807v5)** | 2025-02-25 | <details><summary>Show</summary><p>Formal program specifications play a crucial role in various stages of software development. However, manually crafting formal program specifications is rather difficult, making the job time-consuming and labor-intensive. It is even more challenging to write specifications that correctly and comprehensively describe the semantics of complex programs. To reduce the burden on software developers, automated specification generation methods have emerged. However, existing methods usually rely on predefined templates or grammar, making them struggle to accurately describe the behavior and functionality of complex real-world programs. To tackle this challenge, we introduce SpecGen, a novel technique for formal program specification generation based on Large Language Models. Our key insight is to overcome the limitations of existing methods by leveraging the code comprehension capability of LLMs. The process of SpecGen consists of two phases. The first phase employs a conversational approach that guides the LLM to generate appropriate specifications for a given program. The second phase, designed for where the LLM fails to generate correct specifications, applies four mutation operators to the model-generated specifications and selects verifiable specifications from the mutated ones through a novel heuristic selection strategy. We evaluate SpecGen on two datasets, including the SV-COMP Java category benchmark and a manually constructed dataset. Experimental results demonstrate that SpecGen succeeds in generating verifiable specifications for 279 out of 385 programs, outperforming the existing purely LLM-based approaches and conventional specification generation tools like Houdini and Daikon. Further investigations on the quality of generated specifications indicate that SpecGen can comprehensively articulate the behaviors of the input program.</p></details> |  |
| **[CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming](http://arxiv.org/abs/2502.17835v1)** | 2025-02-25 | <details><summary>Show</summary><p>As programming education becomes more widespread, many college students from non-computer science backgrounds begin learning programming. Collaborative programming emerges as an effective method for instructors to support novice students in developing coding and teamwork abilities. However, due to limited class time and attention, instructors face challenges in monitoring and evaluating the progress and performance of groups or individuals. To address this issue, we collect multimodal data from real-world settings and develop CPVis, an interactive visual analytics system designed to assess student collaboration dynamically. Specifically, CPVis enables instructors to evaluate both group and individual performance efficiently. CPVis employs a novel flower-based visual encoding to represent performance and provides time-based views to capture the evolution of collaborative behaviors. A within-subject experiment (N=22), comparing CPVis with two baseline systems, reveals that users gain more insights, find the visualization more intuitive, and report increased confidence in their assessments of collaboration.</p></details> |  |
| **[Programming with Pixels: Computer-Use Meets Software Engineering](http://arxiv.org/abs/2502.18525v1)** | 2025-02-24 | <details><summary>Show</summary><p>Recent advancements in software engineering (SWE) agents have largely followed a $\textit{tool-based paradigm}$, where agents interact with hand-engineered tool APIs to perform specific tasks. While effective for specialized tasks, these methods fundamentally lack generalization, as they require predefined tools for each task and do not scale across programming languages and domains. We introduce $\texttt{Programming with Pixels}$ (PwP), an agent environment that unifies software development tasks by enabling $\textit{computer-use agents}$-agents that operate directly within an IDE through visual perception, typing, and clicking, rather than relying on predefined tool APIs. To systematically evaluate these agents, we propose $\texttt{PwP-Bench}$, a benchmark that unifies existing SWE benchmarks spanning tasks across multiple programming languages, modalities, and domains under a task-agnostic state and action space. Our experiments demonstrate that general-purpose computer-use agents can approach or even surpass specialized tool-based agents on a variety of SWE tasks without the need for hand-engineered tools. However, our analysis shows that current models suffer from limited visual grounding and fail to exploit many IDE tools that could simplify their tasks. When agents can directly access IDE tools, without visual interaction, they show significant performance improvements, highlighting the untapped potential of leveraging built-in IDE capabilities. Our results establish PwP as a scalable testbed for building and evaluating the next wave of software engineering agents. We release code and data at https://programmingwithpixels.com</p></details> |  |
| **[How Scientists Use Large Language Models to Program](http://arxiv.org/abs/2502.17348v1)** | 2025-02-24 | <details><summary>Show</summary><p>Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization. As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development. We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university. Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries. We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses.</p></details> | Accepted to CHI 2025 |
| **[Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation](http://arxiv.org/abs/2502.16529v1)** | 2025-02-23 | <details><summary>Show</summary><p>Visual programming languages (VPLs) allow users to create programs through graphical interfaces, which results in easier accessibility and their widespread usage in various domains. To further enhance this accessibility, recent research has focused on generating VPL code from user instructions using large language models (LLMs). Specifically, by employing prompting-based methods, these studies have shown promising results. Nevertheless, such approaches can be less effective for industrial VPLs such as Ladder Diagram (LD). LD is a pivotal language used in industrial automation processes and involves extensive domain-specific configurations, which are difficult to capture in a single prompt. In this work, we demonstrate that training-based methods outperform prompting-based methods for LD generation accuracy, even with smaller backbone models. Building on these findings, we propose a two-stage training strategy to further enhance VPL generation. First, we employ retrieval-augmented fine-tuning to leverage the repetitive use of subroutines commonly seen in industrial VPLs. Second, we apply direct preference optimization (DPO) to further guide the model toward accurate outputs, using systematically generated preference pairs through graph editing operations. Extensive experiments on real-world LD data demonstrate that our approach improves program-level accuracy by over 10% compared to supervised fine-tuning, which highlights its potential to advance industrial automation.</p></details> |  |
| **[Tensor Network Structure Search Using Program Synthesis](http://arxiv.org/abs/2502.02711v2)** | 2025-02-22 | <details><summary>Show</summary><p>Tensor networks provide a powerful framework for compressing multi-dimensional data. The optimal tensor network structure for a given data tensor depends on both the inherent data properties and the specific optimality criteria, making tensor network structure search a crucial research problem. Existing solutions typically involve sampling and validating numerous candidate structures; this is computationally expensive, limiting their practical applications. We address this challenge by formulating tensor network structure search as a program synthesis problem and proposing a highly efficient validation method that is based on constraint solving. Specifically, we design a domain specific language: it builds the correspondence between programs and network structures, and uses a novel idea of output-directed splits to compress the search space without hindering the expressiveness. We then propose a synthesis algorithm that can prioritize promising candidates through constraint solving. % Experimental results show that our approach improves search speed by $10\times$ and achieves compression ratios by $1.5\times$ to $3\times$ better than state-of-the-art. Notably, our approach scales to larger tensors that are out of reach by prior work. Finally, we demonstrate that the discovered topologies generalize to data from the same source, achieving compression ratios up to $ 2.4\times$ better than hierarchical Tuckers while maintaining the runtime around $110$ seconds.</p></details> |  |
| **[A Stepwise Distillation Learning Strategy for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks](http://arxiv.org/abs/2309.09809v3)** | 2025-02-22 | <details><summary>Show</summary><p>Recently, Visual Programming (VProg) has emerged as a significant framework for visual reasoning (VR) tasks due to its interpretability and cross-task generality. However, even with invoking powerful pre-trained Vision-Language models (VLMs) as visual sub-modules, the performance of VProg on specific VR tasks is markedly inferior compared to well-trained task-specific networks. Although invoking task-specific models can further enhance the performance of VProg on specific VR tasks, it greatly diminishes the cross-task generalization ability of VProg. Besides, the non-differentiable nature of VProg prevents direct fine-tuning on specific VR tasks for further performance improvement. Attempt to address these issues, we propose SDVP, a Stepwise Distillation learning strategy for non-differentiable VPorg across various VR tasks. Specifically, our SDVP stepwise distills the capabilities of existing, well-trained small task-specific models for decomposed visual sub-tasks in VProg into the much larger VLMs invoked by corresponding visual sub-modules. Besides, distilling the knowledge of little-size task-specific models into pre-trained larger VLMs rather than replacing them helps keep the cross-task abilities of VProgs. Extensive and comprehensive experimental results on different VProg frameworks demonstrate that our SDVP obtains significant performance gains on specific VR benchmarks, i.e., GQA (+2.4\%) and NLVRv2 (+6.2\%) for VisProg and GQA (+6.5\%) and NLVRv2 (+4.0\%) for ViperGPT, and also maintains a promising performance for VProg on unseen and previous VR tasks.</p></details> |  |
| **[Practical programming research of Linear DML model based on the simplest Python code: From the standpoint of novice researchers](http://arxiv.org/abs/2502.16172v1)** | 2025-02-22 | <details><summary>Show</summary><p>This paper presents linear DML models for causal inference using the simplest Python code on a Jupyter notebook based on an Anaconda platform and compares the performance of different DML models. The results show that current Library API technology is not yet sufficient to enable novice Python users to build qualified and high-quality DML models with the simplest coding approach. Novice users attempting to perform DML causal inference using Python still have to improve their mathematical and computer knowledge to adapt to more flexible DML programming. Additionally, the issue of mismatched outcome variable dimensions is also widespread when building linear DML models in Jupyter notebook.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 4 tables, 3 figures</p></details> |
| **[A Mixed-Integer Linear Programming (MILP) for Garment Line Balancing](http://arxiv.org/abs/2502.17508v1)** | 2025-02-22 | <details><summary>Show</summary><p>This applied research article explores the application of Mixed-Integer Linear Programming (MILP) to address line-balancing challenges in the garment industry, focusing on optimizing production processes under multiple constraints. By integrating MILP with Lean Methodology principles, the study demonstrates significant improvements in operational efficiency and cost-effectiveness. The case study, conducted in collaboration with Prof Dr Ray WM Kong, highlights the successful implementation of MILP using IBM CPLEX Studio to optimize production order quantities across online and offline operations. The results reveal a remarkable reduction in labour costs, exceeding 50%, while effectively managing resource capacity and demand constraints. This study not only validates the theoretical underpinnings of MILP in resolving line-balancing issues but also underscores its practical applicability in modernizing garment production. The findings contribute valuable insights into the potential of advanced optimization techniques to enhance competitiveness and sustainability in the garment industry. This abstract succinctly captures the essence of the research, emphasizing the methodology, results, and significance of the study.</p></details> | <details><summary>12 pa...</summary><p>12 pages,9 Figures, 6 Tables. arXiv admin note: substantial text overlap with arXiv:2502.00455</p></details> |
| **[Counting communities in weighted Stochastic Block Models via semidefinite programming](http://arxiv.org/abs/2502.15891v1)** | 2025-02-21 | <details><summary>Show</summary><p>We consider the problem of estimating the number of communities in a weighted balanced Stochastic Block Model. We construct hypothesis tests based on semidefinite programming and with a statistic coming from a GOE matrix to distinguish between any two candidate numbers of communities. This is possible due to a universality result for a semidefinite programming-based function that we also prove. The tests are then used to form a sequential test to estimate the number of communities. Furthermore, we also construct estimators of the communities themselves.</p></details> | <details><summary>This ...</summary><p>This is a first draft. Comments are welcome</p></details> |
| **[Towards Foundation Models for Mixed Integer Linear Programming](http://arxiv.org/abs/2410.08288v2)** | 2025-02-21 | <details><summary>Show</summary><p>Mixed Integer Linear Programming (MILP) is essential for modeling complex decision-making problems but faces challenges in computational tractability and requires expert formulation. Current deep learning approaches for MILP focus on specific problem classes and do not generalize to unseen classes. To address this shortcoming, we take a foundation model training approach, where we train a single deep learning model on a diverse set of MILP problems to generalize across problem classes. As existing datasets for MILP lack diversity and volume, we introduce MILP-Evolve, a novel LLM-based evolutionary framework that is capable of generating a large set of diverse MILP classes with an unlimited amount of instances. We study our methodology on three key learning tasks that capture diverse aspects of MILP: (1) integrality gap prediction, (2) learning to branch, and (3) a new task of aligning MILP instances with natural language descriptions. Our empirical results show that models trained on the data generated by MILP-Evolve achieve significant improvements on unseen problems, including MIPLIB benchmarks. Our work highlights the potential of moving towards a foundation model approach for MILP that can generalize to a broad range of MILP applications. Our code and data are publicly available at https://github.com/microsoft/OptiGuide.</p></details> |  |
| **[A Comprehensive Survey of Linear, Integer, and Mixed-Integer Programming Approaches for Optimizing Resource Allocation in 5G and Beyond Networks](http://arxiv.org/abs/2502.15585v1)** | 2025-02-21 | <details><summary>Show</summary><p>The introduction of 5G networks has significantly advanced communication technology, offering faster speeds, lower latency, and greater capacity. This progress sets the stage for Beyond 5G (B5G) networks, which present new complexity and performance requirements challenges. Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) models have been widely used to model the optimization of resource allocation problems in networks. This paper reviews 103 studies on resource allocation strategies in 5G and B5G, focusing specifically on optimization problems modelled as LP, ILP, and MILP. The selected studies are categorized based on network architectures, types of resource allocation problems, and specific objective functions and constraints. The review also discusses solution methods for NP-hard ILP and MILP problems by categorizing the solution methods into different categories. Additionally, emerging trends, such as integrating AI and machine learning with optimization models, are explored, suggesting promising future research directions in network optimization. The paper concludes that LP, ILP, and MILP models have been widely adopted across various network architectures, resource types, objective functions, and constraints and remain critical to optimizing next-generation networks.</p></details> |  |
| **[Promoting Gender Equality in Competitive Programming: Strategies and Impacts of Affirmative Actions in Programming Marathons in Brazil](http://arxiv.org/abs/2502.15558v1)** | 2025-02-21 | <details><summary>Show</summary><p>In the context of Computing, competitive programming is a relevant area that aims to have students, usually in teams, solve programming challenges, developing skills and competencies in the field. However, female participation remains significantly low and notably distant compared to male participation, even with proven intellectual equity between genders. This research aims to present strategies used to improve female participation in Programming Marathons in Brasil. The developed research is documentary, applied, and exploratory, with actions that generate results for female participation, with affirmative and inclusion actions, an important step towards gender equity in competitive programming.</p></details> | <details><summary>12 pa...</summary><p>12 pages, SBIE (2024), in Portuguese language</p></details> |
| **[Zweistein: A Dynamic Programming Evaluation Function for Einstein Würfelt Nicht!](http://arxiv.org/abs/2502.15547v1)** | 2025-02-21 | <details><summary>Show</summary><p>This paper introduces Zweistein, a dynamic programming evaluation function for Einstein W\"urfelt Nicht! (EWN). Instead of relying on human knowledge to craft an evaluation function, Zweistein uses a data-centric approach that eliminates the need for parameter tuning. The idea is to use a vector recording the distance to the corner of all pieces. This distance vector captures the essence of EWN. It not only outperforms many traditional EWN evaluation functions but also won first place in the TCGA 2023 competition.</p></details> |  |
| **[How Do Programming Students Use Generative AI?](http://arxiv.org/abs/2501.10091v2)** | 2025-02-21 | <details><summary>Show</summary><p>Programming students have a widespread access to powerful Generative AI tools like ChatGPT. While this can help understand the learning material and assist with exercises, educators are voicing more and more concerns about an overreliance on generated outputs and lack of critical thinking skills. It is thus important to understand how students actually use generative AI and what impact this could have on their learning behavior. To this end, we conducted a study including an exploratory experiment with 37 programming students, giving them monitored access to ChatGPT while solving a code authoring exercise. The task was not directly solvable by ChatGPT and required code comprehension and reasoning. While only 23 of the students actually opted to use the chatbot, the majority of those eventually prompted it to simply generate a full solution. We observed two prevalent usage strategies: to seek knowledge about general concepts and to directly generate solutions. Instead of using the bot to comprehend the code and their own mistakes, students often got trapped in a vicious cycle of submitting wrong generated code and then asking the bot for a fix. Those who self-reported using generative AI regularly were more likely to prompt the bot to generate a solution. Our findings indicate that concerns about potential decrease in programmers' agency and productivity with Generative AI are justified. We discuss how researchers and educators can respond to the potential risk of students uncritically over-relying on Generative AI. We also discuss potential modifications to our study design for large-scale replications.</p></details> | <details><summary>prepr...</summary><p>preprint; accepted to ACM International Conference on the Foundations of Software Engineering (FSE) 2025</p></details> |
| **[A fast convergence algorithm based on binary integer programming for expert load balancing in MoE LLMs](http://arxiv.org/abs/2502.15451v1)** | 2025-02-21 | <details><summary>Show</summary><p>MoE (Mixture-of-Expert) architectures appear frequently in large language models, and the number of experts can be over one hundred recently. However, the expert load imbalance problem always happens in MoE model pre-training, which will cause routing collapse or increased computational overhead. In order to balance loads on experts, we propose BIP-Based Balancing, an expert load balancing algorithm based on binary integer programming (BIP). The algorithm maintains an additional vector q that can help change the top-K order of s by solving a binary integer programming with very small time costs. In simulation experiments, we observe that BIP-Based Balancing make imbalance disappoint very fast, while the final sum of routine scores decreases very little. Our algorithm achieves nearly perfect trade-off between expert load balance and pre-training efficiency under the simulation view.</p></details> |  |
| **[Quantum Markov Decision Processes: Dynamic and Semi-Definite Programs for Optimal Solutions](http://arxiv.org/abs/2402.14651v2)** | 2025-02-21 | <details><summary>Show</summary><p>In this paper, building on the formulation of quantum Markov decision processes (q-MDPs) presented in our previous work [{\sc N.~Saldi, S.~Sanjari, and S.~Y\"{u}ksel}, {\em Quantum Markov Decision Processes: General Theory, Approximations, and Classes of Policies}, SIAM Journal on Control and Optimization, 2024], our focus shifts to the development of semi-definite programming approaches for optimal policies and value functions of both open-loop and classical-state-preserving closed-loop policies. First, by using the duality between the dynamic programming and the semi-definite programming formulations of any q-MDP with open-loop policies, we establish that the optimal value function is linear and there exists a stationary optimal policy among open-loop policies. Then, using these results, we establish a method for computing an approximately optimal value function and formulate computation of optimal stationary open-loop policy as a bi-linear program. Next, we turn our attention to classical-state-preserving closed-loop policies. Dynamic programming and semi-definite programming formulations for classical-state-preserving closed-loop policies are established, where duality of these two formulations similarly enables us to prove that the optimal policy is linear and there exists an optimal stationary classical-state-preserving closed-loop policy. Then, similar to the open-loop case, we establish a method for computing the optimal value function and pose computation of optimal stationary classical-state-preserving closed-loop policies as a bi-linear program.</p></details> | 53 pages |
| **[Computation Tree Logic Guided Program Repair](http://arxiv.org/abs/2502.15344v1)** | 2025-02-21 | <details><summary>Show</summary><p>Temporal logics like Computation Tree Logic (CTL) have been widely used as expressive formalisms to capture rich behavioral specifications. CTL can express properties such as reachability, termination, invariants and responsiveness, which are difficult to test. This paper suggests a mechanism for the automated repair of infinite-state programs guided by CTL properties. Our produced patches avoid the overfitting issue that occurs in test-suite-guided repair, where the repaired code may not pass tests outside the given test suite. To realize this vision, we propose a repair framework based on Datalog, a widely used domain-specific language for program analysis, which readily supports nested fixed-point semantics of CTL via stratified negation. Specifically, our framework encodes the program and CTL properties into Datalog facts and rules and performs the repair by modifying the facts to pass the analysis rules. Previous research proposed a generic repair mechanism for Datalog-based analysis in the form of Symbolic Execution of Datalog (SEDL). However, SEDL only supports positive Datalog, which is insufficient for expressing CTL properties. Thus, we extended SEDL to make it applicable to stratified Datalog. Moreover, liveness property violations involve infinite computations, which we handle via a novel loop summarization. Our approach achieves analysis accuracy of 56.6% on a small-scale benchmark and 88.5% on a real-world benchmark, outperforming the best baseline performances of 27.7% and 76.9%. Our approach repairs all detected bugs, which is not achieved by existing tools.</p></details> |  |
| **[Safe Pareto Improvements for Expected Utility Maximizers in Program Games](http://arxiv.org/abs/2403.05103v5)** | 2025-02-21 | <details><summary>Show</summary><p>Agents in mixed-motive coordination problems such as Chicken may fail to coordinate on a Pareto-efficient outcome. Safe Pareto improvements (SPIs) were originally proposed to mitigate miscoordination in cases where players lack probabilistic beliefs as to how their delegates will play a game; delegates are instructed to behave so as to guarantee a Pareto improvement on how they would play by default. More generally, SPIs may be defined as transformations of strategy profiles such that all players are necessarily better off under the transformed profile. In this work, we investigate the extent to which SPIs can reduce downsides of miscoordination between expected utility-maximizing agents. We consider games in which players submit computer programs that can condition their decisions on each other's code, and use this property to construct SPIs using programs capable of renegotiation. We first show that under mild conditions on players' beliefs, each player always prefers to use renegotiation. Next, we show that under similar assumptions, each player always prefers to be willing to renegotiate at least to the point at which they receive the lowest payoff they can attain in any efficient outcome. Thus subjectively optimal play guarantees players at least these payoffs, without the need for coordination on specific Pareto improvements. Lastly, we prove that renegotiation does not guarantee players any improvements on this bound.</p></details> | <details><summary>Accep...</summary><p>Accepted to the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS-25)</p></details> |
| **[Aligning the Objective of LLM-based Program Repair](http://arxiv.org/abs/2404.08877v5)** | 2025-02-21 | <details><summary>Show</summary><p>Large language models (LLMs) have achieved decent results on automated program repair (APR). However, the next token prediction training objective of decoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction objective of current infilling-style methods, which impedes LLMs from fully leveraging pre-trained knowledge for program repair. In addition, while some LLMs can locate and repair bugs in certain functions using the related artifacts (e.g., test cases), existing methods still depend on statement-level fault localization methods to provide a list of buggy hunks for repair. This restriction hinders LLMs from exploring potential patches beyond the given locations. In this paper, we investigate a new approach to adapt LLMs to program repair. Our core insight is that LLM's APR capability can be greatly improved by simply aligning the output to their training objective and allowing them to refine the whole program without first identifying faulty statements. Based on this insight, we designed D4C, a straightforward prompting framework for APR. D4C can repair 180 bugs correctly in Defects4J, with each patch being sampled only 10 times. This surpasses the SOTA APR methods with perfect fault localization by 10% and reduces the patch sampling number by 90%. Our findings reveal that (1) objective alignment is crucial for fully exploiting LLM's pre-trained capability, and (2) replacing the traditional localize-buggy-hunks-then-repair workflow with direct debugging is more effective for LLM-based APR methods. Thus, we believe this paper introduces a new mindset for harnessing LLMs in APR.</p></details> | Accepted by ICSE'25 |
| **[Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning](http://arxiv.org/abs/2502.14215v1)** | 2025-02-20 | <details><summary>Show</summary><p>Smart contracts are highly susceptible to manipulation attacks due to the leakage of sensitive information. Addressing manipulation vulnerabilities is particularly challenging because they stem from inherent data confidentiality issues rather than straightforward implementation bugs. To tackle this by preventing sensitive information leakage, we present PartitionGPT, the first LLM-driven approach that combines static analysis with the in-context learning capabilities of large language models (LLMs) to partition smart contracts into privileged and normal codebases, guided by a few annotated sensitive data variables. We evaluated PartitionGPT on 18 annotated smart contracts containing 99 sensitive functions. The results demonstrate that PartitionGPT successfully generates compilable, and verified partitions for 78% of the sensitive functions while reducing approximately 30% code compared to function-level partitioning approach. Furthermore, we evaluated PartitionGPT on nine real-world manipulation attacks that lead to a total loss of 25 million dollars, PartitionGPT effectively prevents eight cases, highlighting its potential for broad applicability and the necessity for secure program partitioning during smart contract development to diminish manipulation vulnerabilities.</p></details> |  |
| **[Autellix: An Efficient Serving Engine for LLM Agents as General Programs](http://arxiv.org/abs/2502.13965v1)** | 2025-02-19 | <details><summary>Show</summary><p>Large language model (LLM) applications are evolving beyond simple chatbots into dynamic, general-purpose agentic programs, which scale LLM calls and output tokens to help AI agents reason, explore, and solve complex tasks. However, existing LLM serving systems ignore dependencies between programs and calls, missing significant opportunities for optimization. Our analysis reveals that programs submitted to LLM serving engines experience long cumulative wait times, primarily due to head-of-line blocking at both the individual LLM request and the program. To address this, we introduce Autellix, an LLM serving system that treats programs as first-class citizens to minimize their end-to-end latencies. Autellix intercepts LLM calls submitted by programs, enriching schedulers with program-level context. We propose two scheduling algorithms-for single-threaded and distributed programs-that preempt and prioritize LLM calls based on their programs' previously completed calls. Our evaluation demonstrates that across diverse LLMs and agentic workloads, Autellix improves throughput of programs by 4-15x at the same latency compared to state-of-the-art systems, such as vLLM.</p></details> |  |
| **[Where are the marathon Girls?: An Analysis of Female Representation in the Brazilian ICPC Programming Marathons](http://arxiv.org/abs/2502.14020v1)** | 2025-02-19 | <details><summary>Show</summary><p>Education motivated the encouragement of female participation in several areas of science and technology. Programming marathons have grown over the years and are events where programmers compete to solve coding challenges. However, despite scientific evidence that there is no intellectual difference between genders, women's participation is relatively low. This work seeks to understand the reason for this adherence, considering the gender issue in Programming Marathons over the last years, in a real context. This work aims to understand the context of female representativeness in which the intellectual aspects do not differ in gender. Still, there is a considerable discrepancy in female belonging.</p></details> | 9 pages |
| **[AI Software Engineer: Programming with Trust](http://arxiv.org/abs/2502.13767v1)** | 2025-02-19 | <details><summary>Show</summary><p>Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis tools to increase trust in the code. This opinion piece comments on whether LLM agents could dominate software engineering workflows in the future and whether the focus of programming will shift from programming at scale to programming with trust.</p></details> | 5 pages |
| **[AutoTEE: Automated Migration and Protection of Programs in Trusted Execution Environments](http://arxiv.org/abs/2502.13379v1)** | 2025-02-19 | <details><summary>Show</summary><p>Trusted Execution Environments (TEEs) isolate a special space within a device's memory that is not accessible to the normal world (also known as Untrusted Environment), even when the device is compromised. Thus, developers can utilize TEEs to provide strong security guarantees for their programs, making sensitive operations like encrypted data storage, fingerprint verification, and remote attestation protected from malicious attacks. Despite the strong protections offered by TEEs, adapting existing programs to leverage such security guarantees is non-trivial, often requiring extensive domain knowledge and manual intervention, which makes TEEs less accessible to developers. This motivates us to design AutoTEE, the first Large Language Model (LLM)-enabled approach that can automatically identify, partition, transform, and port sensitive functions into TEEs with minimal developer intervention. By manually reviewing 68 repositories, we constructed a benchmark dataset consisting of 385 sensitive functions eligible for transformation, on which AutoTEE achieves a high F1 score of 0.91. AutoTEE effectively transforms these sensitive functions into their TEE-compatible counterparts, achieving success rates of 90\% and 83\% for Java and Python, respectively. We further provide a mechanism to automatically port the transformed code to different TEE platforms, including Intel SGX and AMD SEV, demonstrating that the transformed programs run successfully and correctly on these platforms.</p></details> | 14 pages |
| **[Template-Based Visual Program Distillation](http://arxiv.org/abs/2412.08564v2)** | 2025-02-19 | <details><summary>Show</summary><p>For users with limited computational resources, visual programming or prompting large language models (LLMs) to generate executable code for visual tasks, like visual question answering (VQA), remains largely inaccessible. Even with techniques such as distillation, adapting visual programming to smaller models or specific datasets is still quite challenging due to high annotation costs. We propose a low-cost visual program distillation method that can be used for models with fewer than 1 billion parameters and requires no human-generated program annotations. We achieve this through synthetic data augmentation based on decoupling programs into higher-level skills, called templates, and their corresponding arguments. Experimental results show that, with a relatively small amount of question/answer data, small language models can generate high-quality visual programs with the added benefit of much faster inference.</p></details> |  |
| **[Competitive Programming with Large Reasoning Models](http://arxiv.org/abs/2502.06807v2)** | 2025-02-18 | <details><summary>Show</summary><p>We show that reinforcement learning applied to large language models (LLMs) significantly boosts performance on complex coding and reasoning tasks. Additionally, we compare two general-purpose reasoning models - OpenAI o1 and an early checkpoint of o3 - with a domain-specific system, o1-ioi, which uses hand-engineered inference strategies designed for competing in the 2024 International Olympiad in Informatics (IOI). We competed live at IOI 2024 with o1-ioi and, using hand-crafted test-time strategies, placed in the 49th percentile. Under relaxed competition constraints, o1-ioi achieved a gold medal. However, when evaluating later models such as o3, we find that o3 achieves gold without hand-crafted domain-specific strategies or relaxed constraints. Our findings show that although specialized pipelines such as o1-ioi yield solid improvements, the scaled-up, general-purpose o3 model surpasses those results without relying on hand-crafted inference heuristics. Notably, o3 achieves a gold medal at the 2024 IOI and obtains a Codeforces rating on par with elite human competitors. Overall, these results indicate that scaling general-purpose reinforcement learning, rather than relying on domain-specific techniques, offers a robust path toward state-of-the-art AI in reasoning domains, such as competitive programming.</p></details> |  |
| **[RAMPA: Robotic Augmented Reality for Machine Programming by DemonstrAtion](http://arxiv.org/abs/2410.13412v2)** | 2025-02-18 | <details><summary>Show</summary><p>This paper introduces Robotic Augmented Reality for Machine Programming by Demonstration (RAMPA), the first ML-integrated, XR-driven end-to-end robotic system, allowing training and deployment of ML models such as ProMPs on the fly, and utilizing the capabilities of state-of-the-art and commercially available AR headsets, e.g., Meta Quest 3, to facilitate the application of Programming by Demonstration (PbD) approaches on industrial robotic arms, e.g., Universal Robots UR10. Our approach enables in-situ data recording, visualization, and fine-tuning of skill demonstrations directly within the user's physical environment. RAMPA addresses critical challenges of PbD, such as safety concerns, programming barriers, and the inefficiency of collecting demonstrations on the actual hardware. The performance of our system is evaluated against the traditional method of kinesthetic control in teaching three different robotic manipulation tasks and analyzed with quantitative metrics, measuring task performance and completion time, trajectory smoothness, system usability, user experience, and task load using standardized surveys. Our findings indicate a substantial advancement in how robotic tasks are taught and refined, promising improvements in operational safety, efficiency, and user engagement in robotic programming.</p></details> | <details><summary>This ...</summary><p>This work is the final version submitted to the IEEE RA-L</p></details> |
| **[Performance Evaluation of Large Language Models in Statistical Programming](http://arxiv.org/abs/2502.13117v1)** | 2025-02-18 | <details><summary>Show</summary><p>The programming capabilities of large language models (LLMs) have revolutionized automatic code generation and opened new avenues for automatic statistical analysis. However, the validity and quality of these generated codes need to be systematically evaluated before they can be widely adopted. Despite their growing prominence, a comprehensive evaluation of statistical code generated by LLMs remains scarce in the literature. In this paper, we assess the performance of LLMs, including two versions of ChatGPT and one version of Llama, in the domain of SAS programming for statistical analysis. Our study utilizes a set of statistical analysis tasks encompassing diverse statistical topics and datasets. Each task includes a problem description, dataset information, and human-verified SAS code. We conduct a comprehensive assessment of the quality of SAS code generated by LLMs through human expert evaluation based on correctness, effectiveness, readability, executability, and the accuracy of output results. The analysis of rating scores reveals that while LLMs demonstrate usefulness in generating syntactically correct code, they struggle with tasks requiring deep domain understanding and may produce redundant or incorrect results. This study offers valuable insights into the capabilities and limitations of LLMs in statistical programming, providing guidance for future advancements in AI-assisted coding systems for statistical analysis.</p></details> | 27 pages, 8 figures |
| **[Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming](http://arxiv.org/abs/2205.13687v5)** | 2025-02-17 | <details><summary>Show</summary><p>We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\bar{\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\sqrt{\bar{\alpha}_t}\cdot (x_t - x^\star, \lambda_t - \lambda^\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.</p></details> | <details><summary>72 pa...</summary><p>72 pages, 2 figures, 11 tables</p></details> |
| **[Inferring Accumulative Effects of Higher Order Programs](http://arxiv.org/abs/2408.02791v2)** | 2025-02-17 | <details><summary>Show</summary><p>Many temporal safety properties of higher-order programs go beyond simple event sequencing and require an automaton register (or "accumulator") to express, such as input-dependency, event summation, resource usage, ensuring equal event magnitude, computation cost, etc. Some steps have been made towards verifying more basic temporal event sequences via reductions to fair termination [Murase et al. 2016] or some input-dependent properties through deductive proof systems [Nanjo et al. 2018]. However, there are currently no automated techniques to verify the more general class of register-automaton safety properties of higher-order programs. We introduce an abstract interpretation-based analysis to compute dependent, register-automata effects of recursive, higher-order programs. We capture properties of a program's effects in terms of automata that summarizes the history of observed effects using an accumulator register. The key novelty is a new abstract domain for context-dependent effects, capable of abstracting relations between the program environment, the automaton control state, and the accumulator value. The upshot is a dataflow type and effect system that computes context-sensitive effect summaries. We demonstrate our work via a prototype implementation that computes dependent effect summaries (and validates assertions) for OCaml-like recursive higher order programs. As a basis of comparison, we describe reductions to assertion checking for effect-free programs, and demonstrate that our approach outperforms prior tools Drift and RCaml/PCSat. Overall, across a set of 21 new benchmarks, RCaml/PCSat could not verify any, Drift verified 9 benchmarks, and evDrift verified 19; evDrift also had a 30.5x over Drift on those benchmarks that both tools could solve.</p></details> |  |
| **[Feasibility Evaluation of Quadratic Programs for Constrained Control](http://arxiv.org/abs/2502.12005v1)** | 2025-02-17 | <details><summary>Show</summary><p>This paper presents a computationally-efficient method for evaluating the feasibility of Quadratic Programs (QPs) for online constrained control. Based on the duality principle, we first show that the feasibility of a QP can be determined by the solution of a properly-defined Linear Program (LP). Our analysis yields a LP that can be solved more efficiently compared to the original QP problem, and more importantly, is simpler in form and can be solved more efficiently compared to existing methods that assess feasibility via LPs. The computational efficiency of the proposed method compared to existing methods for feasibility evaluation is demonstrated in comparative case studies as well as a feasible-constraint selection problem, indicating its promise for online feasibility evaluation of optimization-based controllers.</p></details> |  |
| **[Matrix Low-dimensional Qubit Casting Based Quantum Electromagnetic Transient Network Simulation Program](http://arxiv.org/abs/2502.11728v1)** | 2025-02-17 | <details><summary>Show</summary><p>In modern power systems, the integration of converter-interfaced generations requires the development of electromagnetic transient network simulation programs (EMTP) that can capture rapid fluctuations. However, as the power system scales, the EMTP's computing complexity increases exponentially, leading to a curse of dimensionality that hinders its practical application. Facing this challenge, quantum computing offers a promising approach for achieving exponential acceleration. To realize this in noisy intermediate-scale quantum computers, the variational quantum linear solution (VQLS) was advocated because of its robustness against depolarizing noise. However, it suffers data inflation issues in its preprocessing phase, and no prior research has applied quantum computing to high-frequency switching EMT networks.To address these issues, this paper first designs the matrix low-dimension qubit casting (MLQC) method to address the data inflation problem in the preprocessing of the admittance matrix for VQLS in EMT networks. Besides, we propose a real-only quantum circuit reduction method tailored to the characteristics of the EMT network admittance matrices. Finally, the proposed quantum EMTP algorithm (QEMTP) has been successfully verified for EMT networks containing a large number of high-frequency switching elements.</p></details> |  |
| **[Extracting total Amb programs from proofs](http://arxiv.org/abs/2307.12454v2)** | 2025-02-16 | <details><summary>Show</summary><p>We present a logical system CFP (Concurrent Fixed Point Logic) supporting the extraction of nondeterministic and concurrent programs that are provably total and correct. CFP is an intuitionistic first-order logic with inductive and coinductive definitions extended by two propositional operators: Rrestriction, a strengthening of implication, and an operator for total concurrency. The source of the extraction are formal CFP proofs, the target is a lambda calculus with constructors and recursion extended by a constructor Amb (for McCarthy's amb) which is interpreted operationally as globally angelic choice and is used to implement nondeterminism and concurrency. The correctness of extracted programs is proven via an intermediate domain-theoretic denotational semantics. We demonstrate the usefulness of our system by extracting a nondeterministic program that translates infinite Gray code into the signed digit representation. A noteworthy feature of CFP is the fact that the proof rules for restriction and concurrency involve variants of the classical law of excluded middle that would not be interpretable computationally without Amb.This is a revised and extended version of the conference paper with the same title that contains full proofs of all major results.</p></details> | <details><summary>39 pa...</summary><p>39 pages + 4 pages appendix. arXiv admin note: text overlap with arXiv:2104.14669</p></details> |
| **[A Program Logic for Under-approximating Worst-case Resource Usage](http://arxiv.org/abs/2502.11091v1)** | 2025-02-16 | <details><summary>Show</summary><p>Understanding and predicting the worst-case resource usage is crucial for software quality; however, existing methods either over-approximate with potentially loose bounds or under-approximate without asymptotic guarantees. This paper presents a program logic to under-approximate worst-case resource usage, adapting incorrectness logic (IL) to reason quantitatively about resource consumption. We propose quantitative forward and backward under-approximate (QFUA and QBUA) triples, which generalize IL to identify execution paths leading to high resource usage. We also introduce a variant of QBUA that supports reasoning about high-water marks. Our logic is proven sound and complete with respect to a simple IMP-like language, and we demonstrate its utility through case studies involving arrays, pointers, and procedure calls.</p></details> |  |
| **[CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code Generation](http://arxiv.org/abs/2502.10802v1)** | 2025-02-15 | <details><summary>Show</summary><p>Large Language Models (LLMs) have shown remarkable performance in automated code generation. However, existing approaches often rely heavily on pre-defined test cases, which become impractical in scenarios where such cases are unavailable. While prior works explore filtering techniques between programs and test cases, they overlook the refinement of test cases. To address this limitation, we introduce CoCoEvo, a novel LLM-based co-evolution framework that simultaneously evolves programs and test cases. CoCoEvo eliminates the dependency on pre-defined test cases by generating both programs and test cases directly from natural language problem descriptions and function headers. The framework employs specialized evolutionary operators, including LLM-based crossover and mutation operators for program evolution, along with a test case generation operator for test case evolution. Additionally, we propose optimization strategies such as a crossover rate scheduler to balance exploration and convergence, and a multi-objective optimization method for test case selection. Experimental results on multiple state-of-the-art LLMs demonstrate that CoCoEvo surpasses existing methods, achieving state-of-the-art performance in automated code generation and testing. These results underscore the potential of co-evolutionary techniques in advancing the field of automated programming.</p></details> |  |
| **[PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale](http://arxiv.org/abs/2502.10618v1)** | 2025-02-15 | <details><summary>Show</summary><p>Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators' plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors' efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.</p></details> | 21 pages, 11 figures |
| **[Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale](http://arxiv.org/abs/2409.17115v2)** | 2025-02-14 | <details><summary>Show</summary><p>Large language model pre-training has traditionally relied on human experts to craft heuristics for improving the corpora quality, resulting in numerous rules developed to date. However, these rules lack the flexibility to address the unique characteristics of individual example effectively. Meanwhile, applying tailored rules to every example is impractical for human experts. In this paper, we demonstrate that even small language models, with as few as 0.3B parameters, can exhibit substantial data refining capabilities comparable to those of human experts. We introduce Programming Every Example (ProX), a novel framework that treats data refinement as a programming task, enabling models to refine corpora by generating and executing fine-grained operations, such as string normalization, for each individual example at scale. Experimental results show that models pre-trained on ProX-curated data outperform either original data or data filtered by other selection methods by more than 2% across various downstream benchmarks. Its effectiveness spans various model sizes and pre-training corpora, including C4, RedPajama-V2, FineWeb, FineWeb-Edu, and DCLM. Furthermore, ProX exhibits significant potential in domain-specific continual pre-training: without domain specific design, models trained on OpenWebMath refined by ProX outperform human-crafted rule-based methods, improving average accuracy by 7.6% over Mistral-7B, with 14.6% for Llama-2-7B and 20.3% for CodeLlama-7B, all within 10B tokens to be comparable to models like Llemma-7B trained on 200B tokens. Further analysis highlights that ProX significantly saves training FLOPs, offering a promising path for efficient LLM pre-training. We are open-sourcing ProX with >500B corpus, models, and sharing all training and implementation details for reproducible research and future innovation. Code: https://github.com/GAIR-NLP/ProX</p></details> | <details><summary>47 pa...</summary><p>47 pages, 13 figures, 34 tables</p></details> |
| **[Local Reasoning about Probabilistic Behaviour for Classical-Quantum Programs](http://arxiv.org/abs/2308.04741v3)** | 2025-02-14 | <details><summary>Show</summary><p>Verifying the functional correctness of programs with both classical and quantum constructs is a challenging task. The presence of probabilistic behaviour entailed by quantum measurements and unbounded while loops complicate the verification task greatly. We propose a new quantum Hoare logic for local reasoning about probabilistic behaviour by introducing distribution formulas to specify probabilistic properties. We show that the proof rules in the logic are sound with respect to a denotational semantics. To demonstrate the effectiveness of the logic, we formally verify the correctness of non-trivial quantum algorithms including the HHL and Shor's algorithms. Moreover, we embed our logic into the proof assistant Coq. The resulting logical framework, called CoqQLR, can facilitate semi-automated reasoning about classical--quantum programs.</p></details> | <details><summary>34 pa...</summary><p>34 pages. arXiv admin note: text overlap with arXiv:2107.00804</p></details> |
| **[OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code](http://arxiv.org/abs/2405.15568v3)** | 2025-02-14 | <details><summary>Show</summary><p>Open-ended and AI-generating algorithms aim to continuously generate and solve increasingly complex tasks indefinitely, offering a promising path toward more general intelligence. To accomplish this grand vision, learning must occur within a vast array of potential tasks. Existing approaches to automatically generating environments are constrained within manually predefined, often narrow distributions of environment, limiting their ability to create any learning environment. To address this limitation, we introduce a novel framework, OMNI-EPIC, that augments previous work in Open-endedness via Models of human Notions of Interestingness (OMNI) with Environments Programmed in Code (EPIC). OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent's current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simulatable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents' learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: https://dub.sh/omniepic</p></details> |  |
| **[Statistical data analysis for Tourism in Poland in R Programming Environment](http://arxiv.org/abs/2502.10100v1)** | 2025-02-14 | <details><summary>Show</summary><p>This study utilises the R programming language for statistical data analysis to understand Tourism dynamics in Poland. It focuses on methods for data visualisation, multivariate statistics, and hypothesis testing. To investigate the expenditure behavior of tourist, spending patterns, correlations, and associations among variables were analysed in the dataset. The results revealed a significant relationship between accommodation type and the purpose of trip, showing that the purpose of a trip impacts the selection of accommodation. A strong correlation was observed between organizer expenditure and private expenditure, indicating that individual spending are more when the spending on organizing the trip are higher. However, no significant difference was observed in total expenditure across different accommodation types and purpose of the trip revealing that travelers tend to spend similar amounts regardless of their reason for travel or choice of accommodation. Although significant relationships were observed among certain variables, ANOVA could not be applied because the dataset was not able to hold on the normality assumption. In future, the dataset can be explored further to find more meaningful insights. The developed code is available on GitHub: https://github.com/SaadAhmedJamal/DataAnalysis RProgEnv.</p></details> | 5 pages |
| **[DiSciPLE: Learning Interpretable Programs for Scientific Visual Discovery](http://arxiv.org/abs/2502.10060v1)** | 2025-02-14 | <details><summary>Show</summary><p>Visual data is used in numerous different scientific workflows ranging from remote sensing to ecology. As the amount of observation data increases, the challenge is not just to make accurate predictions but also to understand the underlying mechanisms for those predictions. Good interpretation is important in scientific workflows, as it allows for better decision-making by providing insights into the data. This paper introduces an automatic way of obtaining such interpretable-by-design models, by learning programs that interleave neural networks. We propose DiSciPLE (Discovering Scientific Programs using LLMs and Evolution) an evolutionary algorithm that leverages common sense and prior knowledge of large language models (LLMs) to create Python programs explaining visual data. Additionally, we propose two improvements: a program critic and a program simplifier to improve our method further to synthesize good programs. On three different real-world problems, DiSciPLE learns state-of-the-art programs on novel tasks with no prior literature. For example, we can learn programs with 35% lower error than the closest non-interpretable baseline for population density estimation.</p></details> |  |
| **[A Typed Lambda-Calculus for Establishing Trust in Probabilistic Programs](http://arxiv.org/abs/2302.00958v3)** | 2025-02-14 | <details><summary>Show</summary><p>The extensive deployment of probabilistic algorithms has radically changed our perspective on several well-established computational notions. Correctness is probably the most basic one. While a typical probabilistic program cannot be said to compute the correct result, we often have quite strong expectations about the frequency with which it should return certain outputs. In these cases, trust as a generalisation of correctness fares better. One way to understand it is to say that a probabilistic computational process is trustworthy if the frequency of its outputs is compliant with a probability distribution which models its expected behaviour. We present a formal computational framework that formalises this idea. In order to do so, we define a typed lambda-calculus that features operators for conducting experiments at runtime on probabilistic programs and for evaluating whether they compute outputs as determined by a target probability distribution. After proving some fundamental computational properties of the calculus, such as progress and termination, we define a static notion of confidence that allows to prove that our notion of trust behaves correctly with respect to the basic tenets of probability theory.</p></details> |  |
| **[The Ann Arbor Architecture for Agent-Oriented Programming](http://arxiv.org/abs/2502.09903v1)** | 2025-02-14 | <details><summary>Show</summary><p>In this paper, we reexamine prompt engineering for large language models through the lens of automata theory. We argue that language models function as automata and, like all automata, should be programmed in the languages they accept, a unified collection of all natural and formal languages. Therefore, traditional software engineering practices--conditioned on the clear separation of programming languages and natural languages--must be rethought. We introduce the Ann Arbor Architecture, a conceptual framework for agent-oriented programming of language models, as a higher-level abstraction over raw token generation, and provide a new perspective on in-context learning. Based on this framework, we present the design of our agent platform Postline, and report on our initial experiments in agent training.</p></details> |  |
| **[Proof complexity of positive branching programs](http://arxiv.org/abs/2102.06673v4)** | 2025-02-13 | <details><summary>Show</summary><p>We investigate the proof complexity of systems based on positive branching programs, i.e. non-deterministic branching programs (NBPs) where, for any 0-transition between two nodes, there is also a 1-transition. Positive NBPs compute monotone Boolean functions, just like negation-free circuits or formulas, but constitute a positive version of (non-uniform) NL, rather than P or NC1, respectively. The proof complexity of NBPs was investigated in previous work by Buss, Das and Knop, using extension variables to represent the dag-structure, over a language of (non-deterministic) decision trees, yielding the system eLNDT. Our system eLNDT+ is obtained by restricting their systems to a positive syntax, similarly to how the 'monotone sequent calculus' MLK is obtained from the usual sequent calculus LK by restricting to negation-free formulas. Our main result is that eLNDT+ polynomially simulates eLNDT over positive sequents. Our proof method is inspired by a similar result for MLK by Atserias, Galesi and Pudl\'ak, that was recently improved to a bona fide polynomial simulation via works of Je\v{r}\'abek and Buss, Kabanets, Kolokolova and Kouck\'y. Along the way we formalise several properties of counting functions within eLNDT+ by polynomial-size proofs and, as a case study, give explicit polynomial-size poofs of the propositional pigeonhole principle.</p></details> | 35 pages, 6 figures |
| **[Knowledge-Enhanced Program Repair for Data Science Code](http://arxiv.org/abs/2502.09771v1)** | 2025-02-13 | <details><summary>Show</summary><p>This paper introduces DSrepair, a knowledge-enhanced program repair method designed to repair the buggy code generated by LLMs in the data science domain. DSrepair uses knowledge graph based RAG for API knowledge retrieval as well as bug knowledge enrichment to construct repair prompts for LLMs. Specifically, to enable knowledge graph based API retrieval, we construct DS-KG (Data Science Knowledge Graph) for widely used data science libraries. For bug knowledge enrichment, we employ an abstract syntax tree (AST) to localize errors at the AST node level. DSrepair's effectiveness is evaluated against five state-of-the-art LLM-based repair baselines using four advanced LLMs on the DS-1000 dataset. The results show that DSrepair surpasses all five baselines. Specifically, when compared to the second-best baseline, DSrepair demonstrates significant improvements, fixing 44.4%, 14.2%, 20.6%, and 32.1% more buggy code snippets for each of the four evaluated LLMs, respectively. Additionally, it achieves greater efficiency, reducing the number of tokens required per code task by 17.49%, 34.24%, 24.71%, and 17.59%, respectively.</p></details> |  |
| **[API Pack: A Massive Multi-Programming Language Dataset for API Call Generation](http://arxiv.org/abs/2402.09615v6)** | 2025-02-13 | <details><summary>Show</summary><p>We introduce API Pack, a massive multi-programming language dataset containing over one million instruction-API calls for improving the API call generation capabilities of large language models. Our evaluation highlights three key findings: First, fine-tuning on API Pack enables open-source models to outperform GPT-3.5 and GPT-4 in generating code for entirely new API calls. We show this by fine-tuning CodeLlama-13B on 20,000 Python instances from API Pack. Second, fine-tuning on a large dataset in one language, combined with smaller datasets from others, improves API generation accuracy across multiple languages. Third, we confirm the benefits of larger datasets for API generalization, as increasing fine-tuning data to one million instances enhances generalization to new APIs. To support further research, we open-source the API Pack dataset, trained model, and code at https://github.com/zguo0525/API-Pack.</p></details> |  |
| **[A systematic literature review on the application of analytical approaches and mathematical programming in public bus transit network design and operations planning: Part II](http://arxiv.org/abs/2502.19430v1)** | 2025-02-13 | <details><summary>Show</summary><p>Among all public transit modes, bus transit systems stand out as the most prevalent and popular. This prominence has spurred a significant body of research addressing various aspects of bus systems. In the literature, analytical approaches and mathematical programming are predominantly used to explore the Public Bus Transit Network Design Problem and Operations Planning (PBTNDP&OP). Part I of our study presented statistical analyses of literature applying these methodologies to PBTNDP&OP, along with a comprehensive review of analytical papers, highlighting the strengths and weaknesses of each approach. In Part II, we delve into the applications of mathematical programming within PBTNDP&OP, building upon the 15 major sub-categories identified in Part I. We have critically analyzed the identified papers within these sub-categories from various perspectives, including the problems investigated, modeling methods employed, decision variables, network structures, and key findings. This critical review highlights selected papers in each category. Finally, acknowledging existing research gaps, we propose potential extensions for future research. Despite the extensive array of publications, numerous topics still warrant further exploration. Notably, sustainable PBTNDP&OP and challenges associated with integrating emerging technologies are poised to dominate future research agendas.</p></details> |  |
| **[A systematic literature review on the application of analytical approaches and mathematical programming in public bus transit network design and operations planning: Part I](http://arxiv.org/abs/2502.09508v1)** | 2025-02-13 | <details><summary>Show</summary><p>The Public Bus Transit Network Design Problem and Operations Planning (PBTNDP&OP) remains a core research area within transportation, in particular, because of the emergence of new transit technologies and services. Analytical approaches and mathematical programming are the most commonly applied methodologies to study this problem. Many studies utilize either of these two methods, often viewed as competing due to the unique benefits each provides that the other does not. This two-part paper systematically reviews the application of analytical approaches and mathematical programming in PBTNDP&OP, analyzing publications from 1968 to 2021. It begins by comparing analytical methods and mathematical programming through various statistical analyses, including the number of published papers, the most active journals and authors, keyword frequencies, keyword co-occurrence maps, and co-authorship maps. Subsequent analysis of the identified papers includes examinations from multiple perspectives: the problems investigated, modeling methods used, decision variables considered, network structures, and key findings. This is followed by a critical review of selected papers. The paper concludes by discussing the advantages and disadvantages of each approach and suggests potential extensions for future research based on identified gaps in existing studies.</p></details> |  |
| **[Hybrid Answer Set Programming: Foundations and Applications](http://arxiv.org/abs/2502.09235v1)** | 2025-02-13 | <details><summary>Show</summary><p>Answer Set Programming (ASP) is a powerful tool for solving real-world problems. However, many problems involve numeric values and complex constraints beyond the capabilities of standard ASP solvers. Hybrid solvers like CLINGCON and CLINGO[DL] address this by using specialized methods for specific constraints. However, these solvers lack a strong theoretical foundation. This issue has first been addressed by introducing the Logic of Here-and-There with constraints (HT_c) as an extension of the Logic of Here-and-There (HT) and its non-monotone extension Equilibrium Logic. Nowadays, HT serves as a logical foundation for ASP and has facilitated a broader understanding of this paradigm. The idea is that HTC (and other extensions) play an analogous role for hybrid ASP. There remain many open questions about these logics regarding their fundamental characteristics as well as their practical use in solvers, ie. how they can guide the implementation. Having a formal understanding of these hybrid logics is also needed to better understand the inherent structure of the (real-world) problems they are applied to and to improve their representations in ASP. As an example of an application of ASP we use product configuration.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[Relating Answer Set Programming and Many-sorted Logics for Formal Verification](http://arxiv.org/abs/2502.09230v1)** | 2025-02-13 | <details><summary>Show</summary><p>Answer Set Programming (ASP) is an important logic programming paradigm within the field of Knowledge Representation and Reasoning. As a concise, human-readable, declarative language, ASP is an excellent tool for developing trustworthy (especially, artificially intelligent) software systems. However, formally verifying ASP programs offers some unique challenges, such as 1. a lack of modularity (the meanings of rules are difficult to define in isolation from the enclosing program), 2. the ground-and-solve semantics (the meanings of rules are dependent on the input data with which the program is grounded), and 3. limitations of existing tools. My research agenda has been focused on addressing these three issues with the intention of making ASP verification an accessible, routine task that is regularly performed alongside program development. In this vein, I have investigated alternative semantics for ASP based on translations into the logic of here-and-there and many-sorted first-order logic. These semantics promote a modular understanding of logic programs, bypass grounding, and enable us to use automated theorem provers to automatically verify properties of programs.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[Computational methods for Dynamic Answer Set Programming](http://arxiv.org/abs/2502.09228v1)** | 2025-02-13 | <details><summary>Show</summary><p>In our daily lives and industrial settings, we often encounter dynamic problems that require reasoning over time and metric constraints. These include tasks such as scheduling, routing, and production sequencing. Dynamic logics have traditionally addressed these needs but often lack the flexibility and integration required for comprehensive problem modeling. This research aims to extend Answer Set Programming (ASP), a powerful declarative problem-solving approach, to handle dynamic domains effectively. By integrating concepts from dynamic, temporal, and metric logics into ASP, we seek to develop robust systems capable of modeling complex dynamic problems and performing efficient reasoning tasks, thereby enhancing ASPs applicability in industrial contexts.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[Bridging Logic Programming and Deep Learning for Explainability through ILASP](http://arxiv.org/abs/2502.09227v1)** | 2025-02-13 | <details><summary>Show</summary><p>My research explores integrating deep learning and logic programming to set the basis for a new generation of AI systems. By combining neural networks with Inductive Logic Programming (ILP), the goal is to construct systems that make accurate predictions and generate comprehensible rules to validate these predictions. Deep learning models process and analyze complex data, while ILP techniques derive logical rules to prove the network's conclusions. Explainable AI methods, like eXplainable Answer Set Programming (XASP), elucidate the reasoning behind these rules and decisions. The focus is on applying ILP frameworks, specifically ILASP and FastLAS, to enhance explainability in various domains. My test cases span weather prediction, the legal field, and image recognition. In weather forecasting, the system will predict events and provides explanations using FastLAS, with plans to integrate recurrent neural networks in the future. In the legal domain, the research focuses on interpreting vague decisions and assisting legal professionals by encoding Italian legal articles and learning reasoning patterns from Court of Cassation decisions using ILASP. For biological laboratories, we will collaborate with a research group to automate spermatozoa morphology classification for Bull Breeding Soundness Evaluation using YOLO networks and ILP to explain classification outcomes. This hybrid approach aims to bridge the gap between the high performance of deep learning models and the transparency of symbolic reasoning, advancing AI by providing interpretable and trustworthy applications.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[A Prolog Program for Bottom-up Evaluation](http://arxiv.org/abs/2502.09223v1)** | 2025-02-13 | <details><summary>Show</summary><p>This short paper describes a simple and intuitive Prolog program, a metainterpreter, that computes the bottom up meaning of a simple positive Horn clause definition. It involves a simple transformation of the object program rules into metarules, which are then used by a metainterpreter to compute bottom up the model of the original program. The resulting algorithm is a form of semi-naive bottom-up evaluation. We discuss various reasons why this Prolog program is particularly interesting. In particular, this is perhaps the only Prolog program for which I find the use of Prolog's assert/1 to be intrinsic, easily understood, and the best, most perspicuous, way to program an algorithm. This short paper might be best characterized as a Prolog programming pearl.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[On LLM-generated Logic Programs and their Inference Execution Methods](http://arxiv.org/abs/2502.09209v1)** | 2025-02-13 | <details><summary>Show</summary><p>Large Language Models (LLMs) trained on petabytes of data are highly compressed repositories of a significant proportion of the knowledge accumulated and distilled so far. In this paper we study techniques to elicit this knowledge in the form of several classes of logic programs, including propositional Horn clauses, Dual Horn clauses, relational triplets and Definite Clause Grammars. Exposing this knowledge as logic programs enables sound reasoning methods that can verify alignment of LLM outputs to their intended uses and extend their inference capabilities. We study new execution methods for the generated programs, including soft-unification of abducible facts against LLM-generated content stored in a vector database as well as GPU-based acceleration of minimal model computation that supports inference with large LLM-generated programs.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[Autonomous Task Completion Based on Goal-directed Answer Set Programming](http://arxiv.org/abs/2502.09208v1)** | 2025-02-13 | <details><summary>Show</summary><p>Task planning for autonomous agents has typically been done using deep learning models and simulation-based reinforcement learning. This research proposes combining inductive learning techniques with goal-directed answer set programming to increase the explainability and reliability of systems for task breakdown and completion. Preliminary research has led to the creation of a Python harness that utilizes s(CASP) to solve task problems in a computationally efficient way. Although this research is in the early stages, we are exploring solutions to complex problems in simulated task completion.</p></details> | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2024, arXiv:2502.08453</p></details> |
| **[Beyond Non-Degeneracy: Revisiting Certainty Equivalent Heuristic for Online Linear Programming](http://arxiv.org/abs/2501.01716v2)** | 2025-02-13 | <details><summary>Show</summary><p>The Certainty Equivalent heuristic (CE) is a widely-used algorithm for various dynamic resource allocation problems in OR and OM. Despite its popularity, existing theoretical guarantees of CE are limited to settings satisfying restrictive fluid regularity conditions, particularly, the non-degeneracy conditions, under the widely held belief that the violation of such conditions leads to performance deterioration and necessitates algorithmic innovation beyond CE. In this work, we conduct a refined performance analysis of CE within the general framework of online linear programming. We show that CE achieves uniformly near-optimal regret (up to a polylogarithmic factor in $T$) under only mild assumptions on the underlying distribution, without relying on any fluid regularity conditions. Our result implies that, contrary to prior belief, CE effectively beats the curse of degeneracy for a wide range of problem instances with continuous conditional reward distributions, highlighting the distinction of the problem's structure between discrete and non-discrete settings. Our explicit regret bound interpolates between the mild $(\log T)^2$ regime and the worst-case $\sqrt{T}$ regime with a parameter $\beta$ quantifying the minimal rate of probability accumulation of the conditional reward distributions, generalizing prior findings in the multisecretary setting. To achieve these results, we develop novel algorithmic analytical techniques. Drawing tools from the empirical processes theory, we establish strong concentration analysis of the solutions to random linear programs, leading to improved regret analysis under significantly relaxed assumptions. These techniques may find potential applications in broader online decision-making contexts.</p></details> |  |
| **[Do Large Code Models Understand Programming Concepts? Counterfactual Analysis for Code Predicates](http://arxiv.org/abs/2402.05980v3)** | 2025-02-12 | <details><summary>Show</summary><p>Large Language Models' success on text generation has also made them better at code generation and coding tasks. While a lot of work has demonstrated their remarkable performance on tasks such as code completion and editing, it is still unclear as to why. We help bridge this gap by exploring to what degree auto-regressive models understand the logical constructs of the underlying programs. We propose Counterfactual Analysis for Programming Concept Predicates (CACP) as a counterfactual testing framework to evaluate whether Large Code Models understand programming concepts. With only black-box access to the model, we use CACP to evaluate ten popular Large Code Models for four different programming concepts. Our findings suggest that current models lack understanding of concepts such as data flow and control flow.</p></details> |  |
| **[Shadow Program Inversion with Differentiable Planning: A Framework for Unified Robot Program Parameter and Trajectory Optimization](http://arxiv.org/abs/2409.08678v2)** | 2025-02-12 | <details><summary>Show</summary><p>This paper presents SPI-DP, a novel first-order optimizer capable of optimizing robot programs with respect to both high-level task objectives and motion-level constraints. To that end, we introduce DGPMP2-ND, a differentiable collision-free motion planner for serial N-DoF kinematics, and integrate it into an iterative, gradient-based optimization approach for generic, parameterized robot program representations. SPI-DP allows first-order optimization of planned trajectories and program parameters with respect to objectives such as cycle time or smoothness subject to e.g. collision constraints, while enabling humans to understand, modify or even certify the optimized programs. We provide a comprehensive evaluation on two practical household and industrial applications.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 6 figures, accepted at the 2025 IEEE International Conference on Robotics & Automation (ICRA)</p></details> |
| **[Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions](http://arxiv.org/abs/2502.08272v1)** | 2025-02-12 | <details><summary>Show</summary><p>We study weighted pseudorandom generators (WPRGs) and derandomizations for read-once branching programs (ROBPs), which are key problems towards answering the fundamental open question $\mathbf{BPL} \stackrel{?}{=} \mathbf{L}$. Denote $n$ and $w$ as the length and the width of a ROBP. We have the following results. For standard ROBPs, there exists an explicit $\varepsilon$-WPRG with seed length $$ O\left(\frac{\log n\log (nw)}{\max\left\{1,\log\log w-\log\log n\right\}}+\log w \left(\log\log\log w-\log\log\max\left\{2,\frac{\log w}{\log n/\varepsilon}\right\}\right)+\log(1/\varepsilon)\right).$$ When $n = w^{o(1)},$ this is better than the constructions in Hoza (RANDOM 2022), Cohen, Doron, Renard, Sberlo, and Ta-Shma (CCC 2021). For permutation ROBPs with unbounded widths and single accept nodes, there exists an explicit $\varepsilon$-WPRG with seed length $$ O\left( \log n\left( \log\log n + \sqrt{\log(1/\varepsilon)} \right)+\log(1/\varepsilon)\right). $$ This slightly improves the result of Chen, Hoza, Lyu, Tal, and Wu (FOCS 2023). For regular ROBPs with $n \leq 2^{O(\sqrt{\log w})}, \varepsilon = 1/\text{poly} w$, we give a derandomization within space $O(\log w)$, i.e. in $\mathbf{L}$ exactly. This is better than previous results of Ahmadinejad, Kelner, Murtagh, Peebles, Sidford, and Vadhan (FOCS 2020) in this regime. Our main method is based on a recursive application of weighted pseudorandom reductions, which is a natural notion that is used to simplify ROBPs.</p></details> |  |
| **[A new method for reducing algebraic programs to polynomial programs](http://arxiv.org/abs/2502.08210v1)** | 2025-02-12 | <details><summary>Show</summary><p>We consider a generalization of polynomial programs: algebraic programs, which are optimization or feasibility problems with algebraic objectives or constraints. Algebraic functions are defined as zeros of multivariate polynomials. They are a rich set of functions that includes polynomials themselves, but also ratios and radicals, and finite compositions thereof. When an algebraic program is given in terms of radical expressions, a straightforward way of reformulating into a polynomial program is to introduce a new variable for each distinct radical that appears. Hence, the rich theory and algorithms for polynomial programs, including satisfiability via cylindrical algebraic decomposition, infeasibility certificates via Positivstellensatz theorems, and optimization with sum-of-squares programming directly apply to algebraic programs. We propose a different reformulation, that in many cases introduces significantly fewer new variables, and thus produces polynomial programs that are easier to solve. First, we exhibit an algorithm that finds a defining polynomial of an algebraic function given as a radical expression. As a polynomial does not in general define a unique algebraic function, additional constraints need to be added that isolate the algebraic function from others defined by the same polynomial. Using results from real algebraic geometry, we develop an algorithm that generates polynomial inequalities that isolate an algebraic function. This allows us to reformulate an algebraic program into a polynomial one, by introducing only a single new variable for each algebraic function. On modified versions of classic optimization benchmarks with added algebraic terms, our formulation achieves speedups of up to 50x compared to the straightforward reformulation.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 2 figures, 2 tables</p></details> |
| **[Control Barrier Function-Based Quadratic Programming for SafeOperation of Tethered UAVs](http://arxiv.org/abs/2502.08129v1)** | 2025-02-12 | <details><summary>Show</summary><p>Consider an unmanned aerial vehicle (UAV) physically connected to the ground station with a tether operating in a space, tasked with performing precise maneuvers while constrained by the physical limitation of its tether, which prevents it from flying beyond a maximum allowable length. Violating this tether constraint could lead to system failure or operational hazards, making it essential to enforce safety constraints dynamically while ensuring the drone can track desired trajectories accurately. This paper presents a Control Barrier Function Quadratic Programming Framework (CBF-QP) for ensuring the safe and efficient operation of tethered unmanned aerial vehicles (TUAVs). The framework leverages nominal backstepping control to achieve trajectory tracking, augmented with control barrier functions to ensure compliance with the tether constraint. In this proposed method, the tether constraint is directly embedded in the control design and therefore guarantees the TUAV remains within a predefined operational region defined by the maximum tether length while achieving precise trajectory tracking. The effectiveness of the proposed framework is validated through simulations involving set-point tracking, dynamic trajectory following, and disturbances such as incorrect user inputs. The results demonstrate that the TUAV respects the tether constraint ||x(t)||</= Lmax, with tracking errors converging to zero and the control input remaining bounded.</p></details> | <details><summary>Under...</summary><p>Under review at IEEE OJCSYS</p></details> |
| **[On Constructing Finite Automata by Relational Programming](http://arxiv.org/abs/2502.08040v1)** | 2025-02-12 | <details><summary>Show</summary><p>We consider ways to construct a transducer for a given set of input word to output symbol pairs. This is motivated by the need for representing game playing programs in a low-level mathematical format that can be analyzed by algebraic tools. This is different from the classical applications of finite state automata, thus the usual optimization techniques are not directly applicable. Therefore, we use relational programming tools to find minimal transducers realizing a given set of input-output pairs.</p></details> | <details><summary>9 pag...</summary><p>9 pages, 3 figures, final version will be published elsewhere</p></details> |
| **[Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming](http://arxiv.org/abs/2502.07772v1)** | 2025-02-11 | <details><summary>Show</summary><p>Accurate task planning is critical for controlling autonomous systems, such as robots, drones, and self-driving vehicles. Behavior Trees (BTs) are considered one of the most prominent control-policy-defining frameworks in task planning, due to their modularity, flexibility, and reusability. Generating reliable and accurate BT-based control policies for robotic systems remains challenging and often requires domain expertise. In this paper, we present the LLM-GP-BT technique that leverages the Large Language Model (LLM) and Genetic Programming (GP) to automate the generation and configuration of BTs. The LLM-GP-BT technique processes robot task commands expressed in human natural language and converts them into accurate and reliable BT-based task plans in a computationally efficient and user-friendly manner. The proposed technique is systematically developed and validated through simulation experiments, demonstrating its potential to streamline task planning for autonomous systems.</p></details> | <details><summary>Submi...</summary><p>Submitted to IEEE Conference</p></details> |
| **[Learning to Optimize for Mixed-Integer Non-linear Programming](http://arxiv.org/abs/2410.11061v8)** | 2025-02-11 | <details><summary>Show</summary><p>Mixed-integer nonlinear programs (MINLPs) arise in diverse domains such as energy systems and transportation but are notoriously difficult to solve, particularly on a large scale. While learning-to-optimize methods have been successful at continuous optimization, extending them to MINLPs is still challenging due to the integer constraints. To overcome this, we propose a novel deep-learning approach with two learnable correction layers to ensure solution integrality and a post-processing step to improve solution feasibility. Our experiments show that this is the first general method capable of efficiently solving large-scale MINLPs with up to tens of thousands of variables in milliseconds, delivering high-quality solutions even when traditional solvers and heuristics fail. This is the first general learning method for MINLP, successfully solving some of the largest instances reported to date.</p></details> |  |
| **[A Promising Future: Omission Failures in Choreographic Programming](http://arxiv.org/abs/1712.05465v3)** | 2025-02-11 | <details><summary>Show</summary><p>Choreographic programming promises a simple approach to the coding of concurrent and distributed systems: write the collective communication behaviour of a system of processes as a choreography, and then the programs for these processes are automatically compiled by a provably-correct procedure known as endpoint projection. While this promise prompted substantial research, a theory that can deal with realistic communication failures in a distributed network remains elusive. In this work, we provide the first theory of choreographic programming that addresses realistic communication failures taken from the literature of distributed systems: processes can send or receive fewer messages than they should (send and receive omission), and the network can fail at transporting messages (omission failure). Our theory supports the programming of strategies for failure recovery, and a novel static analysis (called robustness) to check for delivery guarantees (at-most-once and exactly-once). Our key technical innovation is a deconstruction of the usual communication primitive in choreographies to allow for independent implementations of the send and receive actions of a communication, while still retaining the static guarantee that these actions will correlate correctly (the essence of choreographic programming). This has two main benefits. First, each side of a communication can adopt its own failure recovery strategy, as in realistic protocols. Second, initiating new communications does not require any (unrealistic) synchronisation over unreliable channels: senders and receivers agree by construction on how each message should be identified. We validate our design via a series of examples -- including two-phase commit, which so far eluded choreographic programming -- and an implementation of our ideas in the choreographic programming language Choral.</p></details> | IMADA-preprint |
| **[Proceedings 40th International Conference on Logic Programming](http://arxiv.org/abs/2502.08453v1)** | 2025-02-11 | <details><summary>Show</summary><p>Since the first conference In Marseille in 1982, the International Conference on Logic Programming (ICLP) has been the premier international event for presenting research in logic programming. These proceedings include technical communications about, and abstracts for presentations given at the 40th ICLP held October 14-17, in Dallas Texas, USA. The papers and abstracts in this volume include the following areas and topics. Formal and operational semantics: including non-monotonic reasoning, probabilistic reasoning, argumentation, and semantic issues of combining logic with neural models. Language design and programming methodologies such as answer set programming. inductive logic programming, and probabilistic programming. Program analysis and logic-based validation of generated programs. Implementation methodologies including constraint implementation, tabling, Logic-based prompt engineering, and the interaction of logic programming with LLMs.</p></details> |  |
| **[Trustworthy Distributed Certification of Program Execution](http://arxiv.org/abs/2402.13792v2)** | 2025-02-11 | <details><summary>Show</summary><p>Verifying the execution of a program is complicated and often limited by the inability to validate the code's correctness. It is a crucial aspect of scientific research, where it is needed to ensure the reproducibility and validity of experimental results. Similarly, in customer software testing, it is difficult for customers to verify that their specific program version was tested or executed at all. Existing state-of-the-art solutions, such as hardware-based approaches, constraint solvers, and verifiable computation systems, do not provide definitive proof of execution, which hinders reliable testing and analysis of program results. In this paper, we propose an innovative approach that combines a prototype programming language called Mona with a certification protocol OCCP to enable the distributed and decentralized re-execution of program segments. Our protocol allows for certification of program segments in a distributed, immutable, and trustworthy system without the need for naive re-execution, resulting in significant improvements in terms of time and computational resources used. We also explore the use of blockchain technology to manage the protocol workflow following other approaches in this space. Our approach offers a promising solution to the challenges of program execution verification and opens up opportunities for further research and development in this area. Our findings demonstrate the efficiency of our approach in reducing the number of program executions compared to existing state-of-the-art methods, thus improving the efficiency of certifying program executions.</p></details> |  |

